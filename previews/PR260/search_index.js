var documenterSearchIndex = {"docs":
[{"location":"maths/hessians/#Hessians-and-symbolic-precomputation","page":"Hessians and symbolic precomputation","title":"Hessians and symbolic precomputation","text":"","category":"section"},{"location":"maths/hessians/","page":"Hessians and symbolic precomputation","title":"Hessians and symbolic precomputation","text":"∇²Σ(::RAMSymbolic) -> pre-allocated array for vec(Σ)θᵀ\n∇²Σ_function(::RAMSymbolic) -> function to overwrite ∇²Σ in place","category":"page"},{"location":"developer/implied/#Custom-implied-types","page":"Custom implied types","title":"Custom implied types","text":"","category":"section"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"We recommend to first read the part Custom loss functions, as the overall implementation is the same and we will describe it here more briefly.","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"Implied types are of subtype SemImplied. To implement your own implied type, you should define a struct","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"struct MyImplied <: SemImplied\n    ...\nend","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"and a method to update!:","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"import StructuralEquationModels: objective!\n\nfunction update!(targets::EvaluationTargets, implied::MyImplied, model::AbstractSemSingle, params)\n\n    if is_objective_required(targets)\n        ...\n    end\n\n    if is_gradient_required(targets)\n        ...\n    end\n    if is_hessian_required(targets)\n        ...\n    end\n\nend","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"As you can see, update gets passed as a first argument targets, which is telling us whether the objective value, gradient, and/or hessian are needed. We can then use the functions is_..._required and conditional on what the optimizer needs, we can compute and store things we want to make available to the loss functions. For example, as we have seen in Second example - maximum likelihood, the RAM implied type computes the model-implied covariance matrix and makes it available via implied.Σ.","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"Just as described in Custom loss functions, you may define a constructor. Typically, this will depend on the specification = ... argument that can be a ParameterTable or a RAMMatrices object.","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"We implement an ImpliedEmpty type in our package that does nothing but serving as an implied field in case you are using a loss function that does not need any implied type at all. You may use it as a template for defining your own implied type, as it also shows how to handle the specification objects:","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"############################################################################################\n### Types\n############################################################################################\n\"\"\"\nEmpty placeholder for models that don't need an implied part.\n(For example, models that only regularize parameters.)\n\n# Constructor\n\n    ImpliedEmpty(;specification, kwargs...)\n\n# Arguments\n- `specification`: either a `RAMMatrices` or `ParameterTable` object\n\n# Examples\nA multigroup model with ridge regularization could be specified as a `SemEnsemble` with one\nmodel per group and an additional model with `ImpliedEmpty` and `SemRidge` for the regularization part.\n\n# Extended help\n\n## Interfaces\n- `params(::RAMSymbolic) `-> Vector of parameter labels\n- `nparams(::RAMSymbolic)` -> Number of parameters\n\n## Implementation\nSubtype of `SemImplied`.\n\"\"\"\nstruct ImpliedEmpty{A, B, C} <: SemImplied\n    hessianeval::A\n    meanstruct::B\n    ram_matrices::C\nend\n\n############################################################################################\n### Constructors\n############################################################################################\n\nfunction ImpliedEmpty(;specification, meanstruct = NoMeanStruct(), hessianeval = ExactHessian(), kwargs...)\n    return ImpliedEmpty(hessianeval, meanstruct, convert(RAMMatrices, specification))\nend\n\n############################################################################################\n### methods\n############################################################################################\n\nupdate!(targets::EvaluationTargets, implied::ImpliedEmpty, par, model) = nothing\n\n############################################################################################\n### Recommended methods\n############################################################################################\n\nupdate_observed(implied::ImpliedEmpty, observed::SemObserved; kwargs...) = implied","category":"page"},{"location":"developer/implied/","page":"Custom implied types","title":"Custom implied types","text":"As you see, similar to Custom loss functions we implement a method for update_observed.","category":"page"},{"location":"performance/sorting/#Model-sorting","page":"Model sorting","title":"Model sorting","text":"","category":"section"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"In RAM notation, the model implied covariance matrix is computed as","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"Sigma = F(I-A)^-1S(I-A)^-TF^T","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"If the model is acyclic, the observed and latent variables can be reordered such that (I-A) is lower triangular. This has the computational benefit that the inversion of lower triangular matrices can be carried out by specialized algorithms.","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"To automatically reorder your variables in a way that makes this optimization possible, we provide a sort! method that can be applied to ParameterTable objects to sort the observed and latent variables from the most exogenous ones to the most endogenous.","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"We use it as","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"sort_vars!(parameter_table)\n\nmodel = Sem(\n    specification = parameter_table,\n    ...\n)","category":"page"},{"location":"performance/sorting/","page":"Model sorting","title":"Model sorting","text":"Models specified from sorted parameter tables will make use of the described optimizations.","category":"page"},{"location":"internals/internals/#Internals-and-Design","page":"Internals and design","title":"Internals and Design","text":"","category":"section"},{"location":"internals/internals/","page":"Internals and design","title":"Internals and design","text":"On the following pages, we document the internals and design of the package. Those informations are no prerequisite for extending the package (as decribed in the developer documentation)!, but they may be useful and hopefully interesting.","category":"page"},{"location":"tutorials/meanstructure/#Models-with-mean-structures","page":"Mean Structures","title":"Models with mean structures","text":"","category":"section"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"To make use of mean structures in your model, you have to","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"Specify your model with a mean structure. The sections Graph interface and RAMMatrices interface both explain how this works.\nBuild your model with a meanstructure. We explain how that works in the following.","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"Lets say you specified A first model as a graph with a meanstructure:","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"using StructuralEquationModels\n\nobserved_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    dem60 ← ind60\n    dem65 ← dem60\n    dem65 ← ind60\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\n    # means\n    Symbol(1) → _(observed_vars)\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = latent_vars, \n    observed_vars = observed_vars)","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"using StructuralEquationModels\n\nobserved_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    dem60 ← ind60\n    dem65 ← dem60\n    dem65 ← ind60\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\n    # means\n    Symbol(1) → _(observed_vars)\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = latent_vars, \n    observed_vars = observed_vars)","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"that is, all observed variable means are estimated freely.","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"To build the model with a meanstructure, we proceed as usual, but pass the argument meanstructure = true. For our example,","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"data = example_data(\"political_democracy\")\n\nmodel = Sem(\n    specification = partable,\n    data = data,\n    meanstructure = true\n)\n\nfit(model)","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"If we build the model by parts, we have to pass the meanstructure = true argument to every part that requires it (when in doubt, simply consult the documentation for the respective part).","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"For our example,","category":"page"},{"location":"tutorials/meanstructure/","page":"Mean Structures","title":"Mean Structures","text":"observed = SemObservedData(specification = partable, data = data, meanstructure = true)\n\nimplied_ram = RAM(specification = partable, meanstructure = true)\n\nml = SemML(observed = observed, meanstructure = true)\n\nmodel = Sem(observed, implied_ram, SemLoss(ml))\n\nfit(model)","category":"page"},{"location":"developer/extending/#Extending-the-package","page":"Extending the package","title":"Extending the package","text":"","category":"section"},{"location":"developer/extending/","page":"Extending the package","title":"Extending the package","text":"As discussed in the section on Model Construction, every Structural Equation Model (Sem) consists of three (four with the optimizer) parts:","category":"page"},{"location":"developer/extending/","page":"Extending the package","title":"Extending the package","text":"(Image: SEM concept typed)","category":"page"},{"location":"developer/extending/","page":"Extending the package","title":"Extending the package","text":"On the following pages, we will explain how you can define your own custom parts and \"plug them in\". There are certain things you have to do to define custom parts and some things you can do to have a more pleasent experience. In general, these requirements fall into the categories","category":"page"},{"location":"developer/extending/","page":"Extending the package","title":"Extending the package","text":"minimal (to use your custom part and fit a Sem with it)\nuse the outer constructor to build a model in a more convenient way\nuse additional functionality like standard errors, fit measures, etc.","category":"page"},{"location":"tutorials/first_model/#A-first-model","page":"A first model","title":"A first model","text":"","category":"section"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"In this tutorial, we will fit an example SEM with our package.  The example we are using is from the lavaan tutorial, so it may be familiar. It looks like this:","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"(Image: Visualization of the Political Democracy model)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We assume the StructuralEquationModels package is already installed. To use it in the current session, we run","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"using StructuralEquationModels","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We then first define the graph of our model in a syntax which is similar to the R-package lavaan:","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"obs_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlat_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → dem65\n\n    # variances\n    _(obs_vars) ↔ _(obs_vars)\n    _(lat_vars) ↔ _(lat_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"obs_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlat_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → dem65\n\n    # variances\n    _(obs_vars) ↔ _(obs_vars)\n    _(lat_vars) ↔ _(lat_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"note: Time to first model\nWhen executing the code from this tutorial the first time in a fresh julia session, you may wonder that it takes quite some time. This is not because the implementation is slow, but because the functions are compiled the first time you use them. Try rerunning the example a second time - you will see that all function executions after the first one are quite fast.","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We then use this graph to define a ParameterTable object","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"partable = ParameterTable(\n    graph,\n    latent_vars = lat_vars, \n    observed_vars = obs_vars)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"load the example data","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"data = example_data(\"political_democracy\")","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"data = example_data(\"political_democracy\")","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"and specify our model as","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"model = Sem(\n    specification = partable,\n    data = data\n)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We can now fit the model via","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"model_fit = fit(model)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"and compute fit measures as","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"fit_measures(model_fit)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"We can also get a bit more information about the fitted model via the details() function:","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"details(model_fit)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"To investigate the parameter estimates, we can update our partable object to contain the new estimates:","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"update_estimate!(partable, model_fit)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"and investigate the solution with","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"details(partable)","category":"page"},{"location":"tutorials/first_model/","page":"A first model","title":"A first model","text":"Congratulations, you fitted and inspected your very first model!  We recommend continuing with Our Concept of a Structural Equation Model.","category":"page"},{"location":"tutorials/constraints/constraints/#Constrained-optimization","page":"Constraints","title":"Constrained optimization","text":"","category":"section"},{"location":"tutorials/constraints/constraints/#Using-the-NLopt-backend","page":"Constraints","title":"Using the NLopt backend","text":"","category":"section"},{"location":"tutorials/constraints/constraints/#Define-an-example-model","page":"Constraints","title":"Define an example model","text":"","category":"section"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"Let's revisit our model from A first model:","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"using StructuralEquationModels\n\nobserved_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + label(:λ₂)*y2 + label(:λ₃)*y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → label(:λₗ)*dem65\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ label(:y3y7)*y7\n    y8 ↔ label(:y8y4)*y4 + y6\n\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = latent_vars, \n    observed_vars = observed_vars)\n\ndata = example_data(\"political_democracy\")\n\nmodel = Sem(\n    specification = partable,\n    data = data\n)\n\nmodel_fit = fit(model)\n\nupdate_estimate!(partable, model_fit)\n\ndetails(partable)","category":"page"},{"location":"tutorials/constraints/constraints/#Define-the-constraints","page":"Constraints","title":"Define the constraints","text":"","category":"section"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"Let's introduce some constraints:","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"Equality constraint: The covariances y3 ↔ y7 and y8 ↔ y4 should sum up to 1.\nInequality constraint: The difference between the loadings dem60 → y2 and dem60 → y3 should be smaller than 0.1\nBound constraint: The directed effect from  ind60 → dem65 should be smaller than 0.5","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"(Of course those constaints only serve an illustratory purpose.)","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"We first need to get the indices of the respective parameters that are invoved in the constraints.  We can look up their labels in the output above, and retrieve their indices as","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"parind = param_indices(model)\nparind[:y3y7] # 29","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"The bound constraint is easy to specify: Just give a vector of upper or lower bounds that contains the bound for each parameter. In our example, only the parameter labeled :λₗ has an upper bound, and the number of total parameters is n_par(model) = 31, so we define","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"upper_bounds = fill(Inf, 31)\nupper_bounds[parind[:λₗ]] = 0.5","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"The equailty and inequality constraints have to be reformulated to be of the form x = 0 or x ≤ 0:","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"y3 ↔ y7 + y8 ↔ y4 - 1 = 0\ndem60 → y2 - dem60 → y3 - 0.1 ≤ 0","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"Now they can be defined as functions of the parameter vector:","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"parind[:y3y7] # 29\nparind[:y8y4] # 30\n# θ[29] + θ[30] - 1 = 0.0\nfunction eq_constraint(θ, gradient)\n    if length(gradient) > 0\n        gradient .= 0.0\n        gradient[29] = 1.0\n        gradient[30] = 1.0\n    end\n    return θ[29] + θ[30] - 1\nend\n\nparind[:λ₂] # 3\nparind[:λ₃] # 4\n# θ[3] - θ[4] - 0.1 ≤ 0\nfunction ineq_constraint(θ, gradient)\n    if length(gradient) > 0\n        gradient .= 0.0\n        gradient[3] = 1.0\n        gradient[4] = -1.0\n    end\n    θ[3] - θ[4] - 0.1\nend","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"If the algorithm needs gradients at an iteration, it will pass the vector gradient that is of the same size as the parameters. With if length(gradient) > 0 we check if the algorithm needs gradients, and if it does, we fill the gradient vector with the gradients  of the constraint w.r.t. the parameters.","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"In NLopt, vector-valued constraints are also possible, but we refer to the documentation for that.","category":"page"},{"location":"tutorials/constraints/constraints/#Fit-the-model","page":"Constraints","title":"Fit the model","text":"","category":"section"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"We now have everything together to specify and fit our model. First, we specify our optimizer backend as","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"using NLopt\n\nconstrained_optimizer = SemOptimizerNLopt(\n    algorithm = :AUGLAG,\n    options = Dict(:upper_bounds => upper_bounds, :xtol_abs => 1e-4),\n    local_algorithm = :LD_LBFGS,\n    equality_constraints = NLoptConstraint(;f = eq_constraint, tol = 1e-8),\n    inequality_constraints = NLoptConstraint(;f = ineq_constraint, tol = 1e-8),\n)","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"As you see, the equality constraints and inequality constraints are passed as keyword arguments, and the bounds are passed as options for the (outer) optimization algorithm. Additionally, for equality and inequality constraints, a feasibility tolerance can be specified that controls if a solution can be accepted, even if it violates the constraints by a small amount.  Especially for equality constraints, it is recommended to allow for a small positive tolerance. In this example, we set both tolerances to 1e-8.","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"warning: Convergence criteria\nWe have often observed that the default convergence criteria in NLopt lead to non-convergence flags. Indeed, this example does not convergence with default criteria. As you see above, we used a realively liberal absolute tolerance in the optimization parameters of 1e-4. This should not be a problem in most cases, as the sampling variance in (almost all) structural equation models  should lead to uncertainty in the parameter estimates that are orders of magnitude larger. We nontheless recommend choosing a convergence criterion with care (i.e. w.r.t. the scale of your parameters), inspecting the solutions for plausibility, and comparing them to unconstrained solutions.","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"model_constrained = Sem(\n    specification = partable,\n    data = data\n)\n\nmodel_fit_constrained = fit(constrained_optimizer, model_constrained)","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"As you can see, the optimizer converged (:XTOL_REACHED) and investigating the solution yields","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"update_partable!(\n    partable,\n    :estimate_constr,\n    param_labels(model_fit_constrained), \n    solution(model_fit_constrained), \n    )\n\ndetails(partable)","category":"page"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"As we can see, the constrained solution is very close to the original solution (compare the columns estimate and estimate_constr), with the difference that the constrained parameters fulfill their constraints.  As all parameters are estimated simultaneously, it is expexted that some unconstrained parameters are also affected (e.g., the constraint on dem60 → y2 leads to a higher estimate of the residual variance y2 ↔ y2).","category":"page"},{"location":"tutorials/constraints/constraints/#Using-the-Optim.jl-backend","page":"Constraints","title":"Using the Optim.jl backend","text":"","category":"section"},{"location":"tutorials/constraints/constraints/","page":"Constraints","title":"Constraints","text":"Information about constrained optimization using Optim.jl can be found in the packages documentation.","category":"page"},{"location":"performance/starting_values/#Starting-values","page":"Starting values","title":"Starting values","text":"","category":"section"},{"location":"performance/starting_values/","page":"Starting values","title":"Starting values","text":"The fit function has a keyword argument that takes either a vector of starting values or a function that takes a model as input to compute starting values. Current options are start_fabin3 for fabin 3 starting values [Hägglund82] or start_simple for simple starting values. Additional keyword arguments to fit are passed to the starting value function. For example,","category":"page"},{"location":"performance/starting_values/","page":"Starting values","title":"Starting values","text":"    fit(\n        model; \n        start_val = start_simple,\n        start_covariances_latent = 0.5\n    )","category":"page"},{"location":"performance/starting_values/","page":"Starting values","title":"Starting values","text":"uses simple starting values with 0.5 as a starting value for covariances between latent variables.","category":"page"},{"location":"performance/starting_values/","page":"Starting values","title":"Starting values","text":"[Hägglund82]: Hägglund, G. (1982). Factor analysis by instrumental variables methods. Psychometrika, 47(2), 209-222.","category":"page"},{"location":"tutorials/specification/parameter_table/#ParameterTable-interface","page":"ParameterTable interface","title":"ParameterTable interface","text":"","category":"section"},{"location":"tutorials/specification/parameter_table/","page":"ParameterTable interface","title":"ParameterTable interface","text":"Altough you can directly specify a parameter table, this is kind of tedious, so at the moment, we dont have a tutorial for this. As lavaan also uses parameter tables to store model specifications, we are working on a way to convert lavaan parameter tables to StructuralEquationModels.jl parameter tables, but this is still WIP.","category":"page"},{"location":"tutorials/specification/parameter_table/#Convert-from-and-to-RAMMatrices","page":"ParameterTable interface","title":"Convert from and to RAMMatrices","text":"","category":"section"},{"location":"tutorials/specification/parameter_table/","page":"ParameterTable interface","title":"ParameterTable interface","text":"To convert a RAMMatrices object to a ParameterTable, simply use partable = ParameterTable(rammatrices).  To convert an object of type ParameterTable to RAMMatrices, you can use ram_matrices = RAMMatrices(partable).","category":"page"},{"location":"performance/symbolic/#Symbolic-precomputation","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"","category":"section"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"In RAM notation, the model implied covariance matrix is computed as","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"Sigma = F(I-A)^-1S(I-A)^-TF^T","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"If the model is acyclic, we can compute","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"(I-A)^-1 = sum_k = 0^n A^k","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"for some n  infty. Typically, the S and A matrices are sparse. In our package, we offer symbolic precomputation of Sigma, nablaSigma and even nabla^2Sigma for acyclic models to optimally exploit this sparsity. To use this feature, simply use the RAMSymbolic implied type for your model.","category":"page"},{"location":"performance/symbolic/","page":"Symbolic precomputation","title":"Symbolic precomputation","text":"This can decrase model fitting time, but will also increase model building time (as we have to carry out the symbolic computations and compile specialised functions). As a result, this is probably not beneficial to use if you only fit a single model, but can lead to great improvements if you fit the same modle to multiple datasets (e.g. to compute bootstrap standard errors).","category":"page"},{"location":"tutorials/specification/ram_matrices/#RAMMatrices-interface","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"","category":"section"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Models can also be specified by an object of type RAMMatrices.  The RAM (reticular action model) specification corresponds to three matrices; the A matrix containing all directed parameters, the S matrix containing all undirected parameters, and the F matrix filtering out latent variables from the model implied covariance.","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"The model implied covariance matrix for the observed variables of a SEM is then computed as","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Sigma = F(I-A)^-1S(I-A)^-TF^T","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"For A first model, the corresponding specification looks like this:","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"\nS =[:θ1   0    0     0     0      0     0     0     0     0     0     0     0     0\n    0     :θ2  0     0     0      0     0     0     0     0     0     0     0     0\n    0     0     :θ3  0     0      0     0     0     0     0     0     0     0     0\n    0     0     0     :θ4  0      0     0     :θ15  0     0     0     0     0     0\n    0     0     0     0     :θ5   0     :θ16  0     :θ17  0     0     0     0     0\n    0     0     0     0     0     :θ6  0      0     0     :θ18  0     0     0     0\n    0     0     0     0     :θ16  0     :θ7   0     0     0     :θ19  0     0     0\n    0     0     0     :θ15 0      0     0     :θ8   0     0     0     0     0     0\n    0     0     0     0     :θ17  0     0     0     :θ9   0     :θ20  0     0     0\n    0     0     0     0     0     :θ18 0      0     0     :θ10  0     0     0     0\n    0     0     0     0     0     0     :θ19  0     :θ20  0     :θ11  0     0     0\n    0     0     0     0     0     0     0     0     0     0     0     :θ12  0     0\n    0     0     0     0     0     0     0     0     0     0     0     0     :θ13  0\n    0     0     0     0     0     0     0     0     0     0     0     0     0     :θ14]\n\nF =[1.0 0 0 0 0 0 0 0 0 0 0 0 0 0\n    0 1 0 0 0 0 0 0 0 0 0 0 0 0\n    0 0 1 0 0 0 0 0 0 0 0 0 0 0\n    0 0 0 1 0 0 0 0 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 0 0 0 0 0 0\n    0 0 0 0 0 1 0 0 0 0 0 0 0 0\n    0 0 0 0 0 0 1 0 0 0 0 0 0 0\n    0 0 0 0 0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 0 0 0 0 1 0 0 0 0 0\n    0 0 0 0 0 0 0 0 0 1 0 0 0 0\n    0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n\nA =[0  0  0  0  0  0  0  0  0  0  0     1.0   0     0\n    0  0  0  0  0  0  0  0  0  0  0     :θ21  0     0\n    0  0  0  0  0  0  0  0  0  0  0     :θ22  0     0\n    0  0  0  0  0  0  0  0  0  0  0     0     1.0   0\n    0  0  0  0  0  0  0  0  0  0  0     0     :θ23  0\n    0  0  0  0  0  0  0  0  0  0  0     0     :θ24  0\n    0  0  0  0  0  0  0  0  0  0  0     0     :θ25  0\n    0  0  0  0  0  0  0  0  0  0  0     0     0     1\n    0  0  0  0  0  0  0  0  0  0  0     0     0     :θ26\n    0  0  0  0  0  0  0  0  0  0  0     0     0     :θ27\n    0  0  0  0  0  0  0  0  0  0  0     0     0     :θ28\n    0  0  0  0  0  0  0  0  0  0  0     0     0     0\n    0  0  0  0  0  0  0  0  0  0  0     :θ29  0     0\n    0  0  0  0  0  0  0  0  0  0  0     :θ30  :θ31  0]\n\nθ = Symbol.(:θ, 1:31)\n\nspec = RAMMatrices(;\n    A = A, \n    S = S, \n    F = F, \n    param_labels = θ,\n    vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8, :ind60, :dem60, :dem65]\n)\n\nmodel = Sem(\n    specification = spec,\n    data = example_data(\"political_democracy\")\n)","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Let's look at this step by step:","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"First, we specify the A, S and F-Matrices.  For a free parameter, we write a Symbol like :θ1 (or any other symbol we like) to the corresponding place in the respective matrix, to constrain parameters to be equal we just use the same Symbol in the respective entries.  To fix a parameter (as in the A-Matrix above), we just write down the number we want to fix it to.  All other entries are 0.","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Second, we specify a vector of symbols containing our parameters:","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"θ = Symbol.(:θ, 1:31)","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Third, we construct an object of type RAMMatrices, passing our matrices and parameters, as well as the column names of our matrices.  Those are quite important, as they will be used to rearrange your data to match it to your RAMMatrices specification.","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"spec = RAMMatrices(;\n    A = A, \n    S = S, \n    F = F, \n    param_labels = θ,\n    vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8, :ind60, :dem60, :dem65]\n)","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"Finally, we construct a model, passing our RAMMatrices as the specification = ... argument.","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"model = Sem(\n    specification = spec,\n    data = example_data(\"political_democracy\")\n)","category":"page"},{"location":"tutorials/specification/ram_matrices/#Meanstructure","page":"RAMMatrices interface","title":"Meanstructure","text":"","category":"section"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"According to the RAM, model implied mean values of the observed variables are computed as","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"mu = F(I-A)^-1M","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"where M is a vector of mean parameters. To estimate the means of the observed variables in our example (and set the latent means to 0), we would specify the model just as before but add ","category":"page"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"...\n\nM = [:x32; :x33; :x34; :x35; :x36; :x37; :x38; :x39; :x40; :x41; :x42; 0; 0; 0]\n\nθ = Symbol.(:θ, 1:42)\n\nspec = RAMMatrices(;\n    ...,\n    M = M)\n\n...\n","category":"page"},{"location":"tutorials/specification/ram_matrices/#Convert-from-and-to-ParameterTables","page":"RAMMatrices interface","title":"Convert from and to ParameterTables","text":"","category":"section"},{"location":"tutorials/specification/ram_matrices/","page":"RAMMatrices interface","title":"RAMMatrices interface","text":"To convert a RAMMatrices object to a ParameterTable, simply use partable = ParameterTable(ram_matrices).  To convert an object of type ParameterTable to RAMMatrices, you can use ram_matrices = RAMMatrices(partable).","category":"page"},{"location":"internals/files/#Files","page":"files","title":"Files","text":"","category":"section"},{"location":"internals/files/","page":"files","title":"files","text":"We briefly describe the file and folder structure of the package.","category":"page"},{"location":"internals/files/#Source-code","page":"files","title":"Source code","text":"","category":"section"},{"location":"internals/files/","page":"files","title":"files","text":"Source code is in the \"src\" folder:","category":"page"},{"location":"internals/files/","page":"files","title":"files","text":"\"src\"","category":"page"},{"location":"internals/files/","page":"files","title":"files","text":"\"StructuralEquationModels.jl\" defines the module and the exported objects\n\"types.jl\" defines all abstract types and the basic type hierarchy\n\"objective_gradient_hessian.jl\" contains methods for computing objective, gradient and hessian values for different model types as well as generic fallback methods\nThe folders \"observed\", \"implied\", and \"loss\" contain implementations of specific subtypes (for example, the \"loss\" folder contains a file \"ML.jl\" that implements the SemML loss function).\n\"optimizer\" contains connections to different optimization backends (aka methods for fit)\n\"optim.jl\": connection to the Optim.jl package\n\"frontend\" contains user-facing functions\n\"specification\" contains functionality for model specification\n\"fit\" contains functionality for model assessment, like fit measures and standard errors\n\"additional_functions\" contains helper functions for simulations, loading artifacts (example data) and various other things","category":"page"},{"location":"internals/files/","page":"files","title":"files","text":"Code for the package extentions can be found in the \"ext\" folder:","category":"page"},{"location":"internals/files/","page":"files","title":"files","text":"\"SEMNLOptExt\" for connection to NLopt.jl.\n\"SEMProximalOptExt\" for connection to ProximalAlgorithms.jl.","category":"page"},{"location":"internals/files/#Tests-and-Documentation","page":"files","title":"Tests and Documentation","text":"","category":"section"},{"location":"internals/files/","page":"files","title":"files","text":"Tests are in the \"test\" folder, documentation in the \"docs\" folder.","category":"page"},{"location":"tutorials/specification/specification/#Model-specification","page":"Model specification","title":"Model specification","text":"","category":"section"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"Two things can be used to specify a model: a parameter table or ram matrices. You can convert them to each other, and to make your life easier, we also provide a way to get parameter tables from graphs.","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"This leads to the following chart:","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"(Image: Specification flowchart)","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"You can enter model specification at each point, but in general (and especially if you come from lavaan), it is the easiest to follow the red arrows: specify a graph object, convert it to a prameter table, and use this parameter table to construct your models ( just like we did in A first model):","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"obs_vars = ...\nlat_vars   = ...\n\ngraph = @StenoGraph begin\n    ...\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = lat_vars, \n    observed_vars = obs_vars)\n\nmodel = Sem(\n    specification = partable,\n    ...\n)","category":"page"},{"location":"tutorials/specification/specification/","page":"Model specification","title":"Model specification","text":"On the following pages, we explain how to enter the specification process at each step, i.e. how to specify models via the Graph interface, the ParameterTable interface, and the RAMMatrices interface.  If you have an OpenMx background, and are familiar with their way of specifying structural equation models via RAM matrices, the RAMMatrices interface may be of interest for you.","category":"page"},{"location":"performance/parametric/#Parametric-types","page":"Parametric Types","title":"Parametric types","text":"","category":"section"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"Recall that a new composite type in julia can be declared as","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"struct MyNewType\n    field1\n    field2\n    ...\nend","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"Often we can speedup computations by declaring our type as a Parametric Type:","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"struct MyNewType{A, B}\n    field1::A\n    field2::B\n    ...\nend","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"giving each field a type and adding them as parameters to our type declaration.","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"Recall our example from Custom loss functions:","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"struct Ridge <: SemLossFunction\n    α\n    I\nend","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"We could also declare it as a parametric type:","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"struct ParametricRidge{X, Y} <: SemLossFunction\n    α::X\n    I::Y\nend","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"Let's see how this might affect performance:","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"function add_α(ridge1, ridge2)\n    return ridge1.α + ridge2.α \nend\n\nmy_ridge_1 = Ridge(2.5, [2,3])\nmy_ridge_2 = Ridge(25.38, [2,3])\n\nmy_parametric_ridge_1 = ParametricRidge(2.1, [2,3])\nmy_parametric_ridge_2 = ParametricRidge(8.34, [2,3])\n\nusing BenchmarkTools\n\n@benchmark add_α($my_ridge_1, $my_ridge_2)\n\n# output\n\nBenchmarkTools.Trial: 10000 samples with 994 evaluations.\n Range (min … max):  16.073 ns …  1.508 μs  ┊ GC (min … max): 0.00% … 98.35%\n Time  (median):     17.839 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   22.846 ns ± 23.564 ns  ┊ GC (mean ± σ):  1.64% ±  1.70%\n\n@benchmark add_α($my_parametric_ridge_1, $my_parametric_ridge_2)\n\n# output\n\nBenchmarkTools.Trial: 10000 samples with 1000 evaluations.\n Range (min … max):  1.371 ns … 20.250 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     2.097 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   2.169 ns ±  0.829 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n","category":"page"},{"location":"performance/parametric/","page":"Parametric Types","title":"Parametric Types","text":"which is quite a difference. To learn more about parametric types, see the this section in the julia documentation.","category":"page"},{"location":"developer/loss/#Custom-loss-functions","page":"Custom loss functions","title":"Custom loss functions","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"As an example, we will implement ridge regularization. Maximum likelihood estimation with ridge regularization consists of optimizing the objective","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"F_ML(theta) + alpha lVert theta_I rVert^2_2","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Since we allow for the optimization of sums of loss functions, and the maximum likelihood loss function already exists, we only need to implement the ridge part (and additionally get ridge regularization for WLS and FIML estimation for free).","category":"page"},{"location":"developer/loss/#Minimal","page":"Custom loss functions","title":"Minimal","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"using StructuralEquationModels","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"To define a new loss function, you have to define a new type that is a subtype of SemLossFunction:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"struct Ridge <: SemLossFunction\n    α\n    I\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"We store the hyperparameter α and the indices I of the parameters we want to regularize.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Additionaly, we need to define a method of the function evaluate! to compute the objective:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"import StructuralEquationModels: evaluate!\n\nevaluate!(objective::Number, gradient::Nothing, hessian::Nothing, ridge::Ridge, model::AbstractSem, par) = \n  ridge.α * sum(i -> par[i]^2, ridge.I)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"The function evaluate! recognizes by the types of the arguments objective, gradient and hessian whether it should compute the objective value, gradient or hessian of the model w.r.t. the parameters. In this case, gradient and hessian are of type Nothing, signifying that they should not be computed, but only the objective value.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"That's all we need to make it work! For example, we can now fit A first model with ridge regularization:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"We first give some parameters labels to be able to identify them as targets for the regularization:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"observed_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → label(:a)*dem60\n    dem60 → label(:b)*dem65\n    ind60 → label(:c)*dem65\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = latent_vars,\n    observed_vars = observed_vars\n)\n\nparameter_indices = getindex.([param_indices(partable)], [:a, :b, :c])\nmyridge = Ridge(0.01, parameter_indices)\n\nmodel = SemFiniteDiff(\n    specification = partable,\n    data = example_data(\"political_democracy\"),\n    loss = (SemML, myridge)\n)\n\nmodel_fit = fit(model)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"This is one way of specifying the model - we now have one model with multiple loss functions. Because we did not provide a gradient for Ridge, we have to specify a SemFiniteDiff model that computes numerical gradients with finite difference approximation.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Note that the last argument to the objective! method is the whole model. Therefore, we can access everything that is stored inside our model everytime we compute the objective value for our loss function. Since ridge regularization is a very easy case, we do not need to do this. But maximum likelihood estimation for example depends on both the observed and the model implied covariance matrix. See Second example - maximum likelihood for information on how to do that.","category":"page"},{"location":"developer/loss/#Improve-performance","page":"Custom loss functions","title":"Improve performance","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"By far the biggest improvements in performance will result from specifying analytical gradients. We can do this for our example:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"function evaluate!(objective, gradient, hessian::Nothing, ridge::Ridge, model::AbstractSem, par)\n    # compute gradient\n    if !isnothing(gradient)\n        fill!(gradient, 0)\n        gradient[ridge.I] .= 2 * ridge.α * par[ridge.I]\n    end\n    # compute objective\n    if !isnothing(objective) \n        return ridge.α * sum(i -> par[i]^2, ridge.I)\n    end\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"As you can see, in this method definition, both objective and gradient can be different from nothing. We then check whether to compute the objective value and/or the gradient with isnothing(objective)/isnothing(gradient). This syntax makes it possible to compute objective value and gradient at the same time, which is beneficial when the the objective and gradient share common computations.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Now, instead of specifying a SemFiniteDiff, we can use the normal Sem constructor:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"model_new = Sem(\n    specification = partable,\n    data = example_data(\"political_democracy\"),\n    loss = (SemML, myridge)\n)\n\nmodel_fit = fit(model_new)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"The results are the same, but we can verify that the computational costs are way lower (for this, the julia package BenchmarkTools has to be installed):","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"using BenchmarkTools\n\n@benchmark fit(model)\n\n@benchmark fit(model_new)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"The exact results of those benchmarks are of course highly depended an your system (processor, RAM, etc.), but you should see that the median computation time with analytical gradients drops to about 5% of the computation without analytical gradients.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Additionally, you may provide analytic hessians by writing a respective method for evaluate!. However, this will only matter if you use an optimization algorithm that makes use of the hessians. Our default algorithmn LBFGS from the package Optim.jl does not use hessians (for example, the Newton algorithmn from the same package does).","category":"page"},{"location":"developer/loss/#Convenient","page":"Custom loss functions","title":"Convenient","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"To be able to build the model with the Outer Constructor, you need to add a constructor for your loss function that only takes keyword arguments and allows for passing optional additional kewyword arguments. A constructor is just a function that creates a new instance of your type:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"function MyLoss(;arg1 = ..., arg2, kwargs...)\n    ...\n    return MyLoss(...)\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"All keyword arguments that a user passes to the Sem constructor are passed to your loss function. In addition, all previously constructed parts of the model (implied and observed part) are passed as keyword arguments as well as the number of parameters n_par = ..., so your constructor may depend on those. For example, the constructor for SemML in our package depends on the additional argument meanstructure as well as the observed part of the model to pre-allocate arrays of the same size as the observed covariance matrix and the observed mean vector:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"function SemML(;observed, meanstructure = false, approx_H = false, kwargs...)\n\n    isnothing(obs_mean(observed)) ?\n        meandiff = nothing :\n        meandiff = copy(obs_mean(observed))\n\n    return SemML(\n        similar(obs_cov(observed)),\n        similar(obs_cov(observed)),\n        meandiff,\n        approx_H,\n        Val(meanstructure)\n        )\nend","category":"page"},{"location":"developer/loss/#Additional-functionality","page":"Custom loss functions","title":"Additional functionality","text":"","category":"section"},{"location":"developer/loss/#Update-observed-data","page":"Custom loss functions","title":"Update observed data","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"If you are planing a simulation study where you have to fit the same model to many different datasets, it is computationally beneficial to not build the whole model completely new everytime you change your data. Therefore, we provide a function to update the data of your model, replace_observed(model(semfit); data = new_data). However, we can not know beforehand in what way your loss function depends on the specific datasets. The solution is to provide a method for update_observed. Since Ridge does not depend on the data at all, this is quite easy:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"import StructuralEquationModels: update_observed\n\nupdate_observed(ridge::Ridge, observed::SemObserved; kwargs...) = ridge","category":"page"},{"location":"developer/loss/#Access-additional-information","page":"Custom loss functions","title":"Access additional information","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"If you want to provide a way to query information about loss functions of your type, you can provide functions for that:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"hyperparameter(ridge::Ridge) = ridge.α\nregularization_indices(ridge::Ridge) = ridge.I","category":"page"},{"location":"developer/loss/#Second-example-maximum-likelihood","page":"Custom loss functions","title":"Second example - maximum likelihood","text":"","category":"section"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Let's make a sligtly more complicated example: we will reimplement maximum likelihood estimation.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"To keep it simple, we only cover models without a meanstructure. The maximum likelihood objective is defined as","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"F_ML = log det Sigma_i + mathrmtrleft(Sigma_i^-1 Sigma_o right)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"where Sigma_i is the model implied covariance matrix and Sigma_o is the observed covariance matrix. We can query the model implied covariance matrix from the implied par of our model, and the observed covariance matrix from the observed path of our model.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"To get information on what we can access from a certain implied or observed type, we can check it`s documentation an the pages API - model parts or via the help mode of the REPL:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"julia>?\n\nhelp?> RAM\n\nhelp?> SemObservedData","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"We see that the model implied covariance matrix can be assessed as Σ(implied) and the observed covariance matrix as obs_cov(observed).","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"With this information, we write can implement maximum likelihood optimization as","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"struct MaximumLikelihood <: SemLossFunction end\n\nusing LinearAlgebra\nimport StructuralEquationModels: obs_cov, evaluate!\n\nfunction evaluate!(objective::Number, gradient::Nothing, hessian::Nothing, semml::MaximumLikelihood, model::AbstractSem, par)\n    # access the model implied and observed covariance matrices\n    Σᵢ = implied(model).Σ\n    Σₒ = obs_cov(observed(model))\n    # compute the objective\n    if isposdef(Symmetric(Σᵢ)) # is the model implied covariance matrix positive definite?\n        return logdet(Σᵢ) + tr(inv(Σᵢ)*Σₒ)\n    else\n        return Inf\n    end\nend","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"to deal with eventual non-positive definiteness of the model implied covariance matrix, we chose the pragmatic way of returning infinity whenever this is the case.","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"Let's specify and fit a model:","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"model_ml = SemFiniteDiff(\n    specification = partable,\n    data = example_data(\"political_democracy\"),\n    loss = MaximumLikelihood()\n)\n\nmodel_fit = fit(model_ml)","category":"page"},{"location":"developer/loss/","page":"Custom loss functions","title":"Custom loss functions","text":"If you want to differentiate your own loss functions via automatic differentiation, check out the AutoDiffSEM package.","category":"page"},{"location":"developer/observed/#Custom-observed-types","page":"Custom observed types","title":"Custom observed types","text":"","category":"section"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"The implementation of new observed types is very similar to loss functions, so we will just go over it briefly (for additional information, revisit Custom loss functions).","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"First, we need to define a new struct that is a subtype of SemObserved:","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"struct MyObserved <: SemObserved\n    ...\nend","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"Additionally, we can write an outer constructor that will typically depend on the keyword argument data = ...:","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"function MyObserved(;data, kwargs...)\n    ...\n    return MyObserved(...)\nend","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"To compute some fit indices, you need to provide methods for","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"# Number of samples (observations) in the dataset\nnsamples(observed::MyObserved) = ...\n# Number of observed variables\nnobserved_vars(observed::MyObserved) = ...","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"As always, you can add additional methods for properties that implied types and loss function want to access, for example (from the SemObservedData implementation):","category":"page"},{"location":"developer/observed/","page":"Custom observed types","title":"Custom observed types","text":"obs_cov(observed::SemObservedData) = observed.obs_cov","category":"page"},{"location":"tutorials/collection/collection/#Collections","page":"Collections","title":"Collections","text":"","category":"section"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"With StructuralEquationModels.jl, you can fit weighted sums of structural equation models.  The most common use case for this are Multigroup models.  Another use case may be optimizing the sum of loss functions for some of which you do know the analytic gradient, but not for others.  In this case, you can optimize the sum of a Sem and a SemFiniteDiff (or any other differentiation method).","category":"page"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"To use this feature, you have to construct a SemEnsemble model, which is actually quite easy:","category":"page"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"# models\nmodel_1 = Sem(...)\n\nmodel_2 = SemFiniteDiff(...)\n\nmodel_3 = Sem(...)\n\nmodel_ensemble = SemEnsemble(model_1, model_2, model_3)","category":"page"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"So you just construct the individual models (however you like) and pass them to SemEnsemble. You may also pass a vector of weigths to SemEnsemble. By default, those are set to N_modelN_total, i.e. each model is weighted by the number of observations in it's data (which matches the formula for multigroup models).","category":"page"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"Multigroup models can also be specified via the graph interface; for an example, see Multigroup models.","category":"page"},{"location":"tutorials/collection/collection/#API-collections","page":"Collections","title":"API - collections","text":"","category":"section"},{"location":"tutorials/collection/collection/","page":"Collections","title":"Collections","text":"SemEnsemble\nAbstractSemCollection","category":"page"},{"location":"tutorials/collection/collection/#StructuralEquationModels.SemEnsemble","page":"Collections","title":"StructuralEquationModels.SemEnsemble","text":"(1) SemEnsemble(models...; weights = nothing, kwargs...)\n\n(2) SemEnsemble(;specification, data, groups, column = :group, kwargs...)\n\nConstructor for ensemble models. (2) can be used to conveniently specify multigroup models.\n\nArguments\n\nmodels...: AbstractSems.\nweights::Vector:  Weights for each model. Defaults to the number of observed data points.\nspecification::EnsembleParameterTable: Model specification.\ndata::DataFrame: Observed data. Must contain a column of type Vector{Symbol} that contains the group.\ngroups::Vector{Symbol}: Group names.\ncolumn::Symbol: Name of the column in data that contains the group.\n\nAll additional kwargs are passed down to the model parts.\n\nReturns a SemEnsemble with fields\n\nn::Int: Number of models.\nsems::Tuple: AbstractSems.\nweights::Vector: Weights for each model.\nparam_labels::Vector: Stores parameter labels and their position.\n\nFor instructions on multigroup models, see the online documentation.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/collection/collection/#StructuralEquationModels.AbstractSemCollection","page":"Collections","title":"StructuralEquationModels.AbstractSemCollection","text":"Supertype for all collections of multiple SEMs\n\n\n\n\n\n","category":"type"},{"location":"tutorials/construction/construction/#Model-Construction","page":"Model Construction","title":"Model Construction","text":"","category":"section"},{"location":"tutorials/construction/construction/","page":"Model Construction","title":"Model Construction","text":"There are two different ways of constructing a SEM in our package. You can use the Outer Constructor or Build by parts. The final models will be the same, the outer constructor just has some sensible defaults that make your life easier. All tutorials until now used the outer constructor Sem(specification = ..., data = ..., ...), which is normally the more convenient way. However, our package is build for extensibility, so there may be cases where user-defined parts of a model do not work with the outer constructor. Therefore, building the model by parts is always available as a fallback.","category":"page"},{"location":"tutorials/specification/graph_interface/#Graph-interface","page":"Graph interface","title":"Graph interface","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/#Workflow","page":"Graph interface","title":"Workflow","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"As discussed before, when using the graph interface, you can specify your model as a graph","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"graph = @StenoGraph begin\n    ...\nend","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"and convert it to a ParameterTable to construct your models:","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"obs_vars = ...\nlat_vars   = ...\n\npartable = ParameterTable(\n    graph,\n    latent_vars = lat_vars, \n    observed_vars = obs_vars)\n\nmodel = Sem(\n    specification = partable,\n    ...\n)","category":"page"},{"location":"tutorials/specification/graph_interface/#Parameters","page":"Graph interface","title":"Parameters","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"In general, there are two different types of parameters: directed and indirected parameters. A directed parameter from the variable x to y can be specified as x → y (or equivalently as y ← x); an undirected parameter as x ↔ y. We allow multiple variables on both sides of an arrow, for example x → [y z] or [a b] → [c d]. The later specifies element wise edges; that is its the same as a → c; b → d. If you want edges corresponding to the cross-product, we have the double lined arrow [a b] ⇒ [c d], corresponding to a → c; a → d; b → c; b → d. The undirected arrows ↔ (element-wise) and ⇔ (crossproduct) behave the same way.","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"note: Unicode symbols in julia\nThe → symbol is a unicode symbol allowed in julia (among many others; see this list). You can enter it in the julia REPL or the vscode IDE by typing \\to followed by hitting tab. Similarly, ← = \\leftarrow,\n↔ = \\leftrightarrow,\n⇒ = \\Rightarrow,\n⇐ = \\Leftarrow,\n⇔ = \\LeftrightarrowThis may seem cumbersome at first, but with some practice allows you to specify your models in a really elegant way: [x₁ x₂ x₃] ← ξ → η → [y₁ y₂ y₃].","category":"page"},{"location":"tutorials/specification/graph_interface/#Options","page":"Graph interface","title":"Options","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"The graph syntax allows you to fix parameters to specific values, label them, and encode equality constraints by giving different parameters the same label. The following syntax example","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"graph = @StenoGraph begin\n\n    ξ₁ → fixed(1.0)*x1 + x2 + label(:a)*x3\n    ξ₂ → fixed(1.0)*x4 + x5 + label(:λ₁)*x6\n    ξ₃ → fixed(NaN)*x7 + x8 + label(:λ₁)*x9\n\n    ξ₃ ↔ fixed(1.0)*ξ₃\nend","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"would ","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"fix the directed effects from ξ₁ to x1 and from ξ₂ to x2 to 1\nleave the directed effect from ξ₃ to x7 free but instead restrict the variance of ξ₃ to 1\ngive the effect from ξ₁ to x3 the label :a (which can be convenient later if you want to retrieve information from your model about that specific parameter)\nconstrain the effect from ξ₂ to x6 and ξ₃ to x9 to be equal as they are both labeled the same.","category":"page"},{"location":"tutorials/specification/graph_interface/#Using-variables-inside-the-graph-specification","page":"Graph interface","title":"Using variables inside the graph specification","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"As you saw above and in the A first model example, the graph object needs to be converted to a parameter table:","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"partable = ParameterTable(\n    graph,\n    latent_vars = lat_vars, \n    observed_vars = obs_vars)","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"The ParameterTable constructor also needs you to specify a vector of observed and latent variables, in the example above this would correspond to","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"obs_vars = [:x1 :x2 :x3 :x4 :x5 :x6 :x7 :x8 :x9]\nlat_vars   = [:ξ₁ :ξ₂ :ξ₃]","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"The variable names (:x1) have to be symbols, the syntax :something creates an object of type Symbol. But you can also use vectors of symbols inside the graph specification, escaping them with _(...). For example, this graph specification","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"@StenoGraph begin\n    _(obs_vars) ↔ _(obs_vars)\n    _(lat_vars) ⇔ _(lat_vars)\nend","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"creates undirected effects coresponding to ","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"the variances of all observed variables and\nthe variances plus covariances of all latent variables","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"So if you want to work with a subset of variables, simply specify a vector of symbols somevars = [...], and inside the graph specification, refer to them as _(somevars).","category":"page"},{"location":"tutorials/specification/graph_interface/#Meanstructure","page":"Graph interface","title":"Meanstructure","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"Mean parameters are specified as a directed effect from 1 to the respective variable. In our example above, to estimate a mean parameter for all observed variables, we may write","category":"page"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"@StenoGraph begin\n    Symbol(1) → _(obs_vars)\nend","category":"page"},{"location":"tutorials/specification/graph_interface/#Further-Reading","page":"Graph interface","title":"Further Reading","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/#What's-this-strange-looking-@-thing?","page":"Graph interface","title":"What's this strange looking @-thing?","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"The syntax to specify graphs (@StenoGraph) may seem a bit strange if you are not familiar with the julia language. It is called a macro, but explaining this concept in detail is beyond this documentation (and not necessary to understand to specify models). However, if you want to know more about it, you may have a look at the respective part of the manual.","category":"page"},{"location":"tutorials/specification/graph_interface/#The-StenoGraphs-Package","page":"Graph interface","title":"The StenoGraphs Package","text":"","category":"section"},{"location":"tutorials/specification/graph_interface/","page":"Graph interface","title":"Graph interface","text":"Behind the scenes, we are using the StenoGraphs package to specify our graphs. It makes a domain specific language available that allows you to specify graphs with arbitrary information attached to its edges and nodes (for structural equation models, this may be the name or the value of a parameter). Is also allows you to specify your own types to \"attach\" to the graph, called a Modifier. So if you contemplate about writing your own modifier (e.g., to mark a variable as ordinal, an effect as quadratic, ...), please refer to the StenoGraphs documentation.","category":"page"},{"location":"tutorials/backends/nlopt/#Using-NLopt.jl","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"","category":"section"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"SemOptimizerNLopt implements the connection to NLopt.jl. It is only available if the NLopt package is loaded alongside StructuralEquationModel.jl in the running Julia session. It takes a bunch of arguments:","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"    •  algorithm: optimization algorithm\n\n    •  options::Dict{Symbol, Any}: options for the optimization algorithm\n\n    •  local_algorithm: local optimization algorithm\n\n    •  local_options::Dict{Symbol, Any}: options for the local optimization algorithm\n\n    •  equality_constraints::Vector{NLoptConstraint}: vector of equality constraints\n\n    •  inequality_constraints::Vector{NLoptConstraint}: vector of inequality constraints","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"Constraints are explained in the section on Constrained optimization.","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"The defaults are LBFGS as the optimization algorithm and the standard options from NLopt.jl. We can choose something different:","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"using NLopt\n\nmy_optimizer = SemOptimizerNLopt(;\n    algorithm = :AUGLAG,\n    options = Dict(:maxeval => 200),\n    local_algorithm = :LD_LBFGS,\n    local_options = Dict(:ftol_rel => 1e-6)\n)","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"This uses an augmented lagrangian method with LBFGS as the local optimization algorithm, stops at a maximum of 200 evaluations and uses a relative tolerance of the objective value of 1e-6 as the stopping criterion for the local algorithm.","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"To see how to use the optimizer to actually fit a model now, check out the Model fitting section.","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"In the NLopt docs, you can find explanations about the different algorithms and a tutorial that also explains the different options.","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"To choose an algorithm, just pass its name without the 'NLOPT_' prefix (for example, 'NLOPT_LD_SLSQP' can be used by passing algorithm = :LD_SLSQP).","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"The README of the julia package may also be helpful, and provides a list of options:","category":"page"},{"location":"tutorials/backends/nlopt/","page":"Using NLopt.jl","title":"Using NLopt.jl","text":"algorithm\nstopval\nftol_rel\nftol_abs\nxtol_rel\nxtol_abs\nconstrtol_abs\nmaxeval\nmaxtime\ninitial_step\npopulation\nseed\nvector_storage","category":"page"},{"location":"performance/simulation/#Simulation-studies","page":"Simulation studies","title":"Simulation studies","text":"","category":"section"},{"location":"performance/simulation/#Replace-observed-data","page":"Simulation studies","title":"Replace observed data","text":"","category":"section"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"In simulation studies, a common task is fitting the same model to many different datasets. It would be a waste of resources to reconstruct the complete model for each dataset. We therefore provide the function replace_observed to change the observed part of a model, without necessarily reconstructing the other parts.","category":"page"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"For the A first model, you would use it as","category":"page"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"using StructuralEquationModels\n\nobserved_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → dem65\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = latent_vars, \n    observed_vars = observed_vars\n)","category":"page"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"data = example_data(\"political_democracy\")\n\ndata_1 = data[1:30, :]\n\ndata_2 = data[31:75, :]\n\nmodel = Sem(\n    specification = partable,\n    data = data_1\n)\n\nmodel_updated = replace_observed(model; data = data_2, specification = partable)","category":"page"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"If you are building your models by parts, you can also update each part seperately with the function update_observed. For example,","category":"page"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"\nnew_observed = SemObservedData(;data = data_2, specification = partable)\n\nmy_optimizer = SemOptimizerOptim()\n\nnew_optimizer = update_observed(my_optimizer, new_observed)","category":"page"},{"location":"performance/simulation/#Multithreading","page":"Simulation studies","title":"Multithreading","text":"","category":"section"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"danger: Thread safety\nThis is only relevant when you are planning to fit updated models in parallelModels generated by replace_observed may share the same objects in memory (e.g. some parts of  model and model_updated are the same objects in memory.) Therefore, fitting both of these models in parallel will lead to race conditions,  possibly crashing your computer. To avoid these problems, you should copy model before updating it.","category":"page"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"Taking into account the warning above, fitting multiple models in parallel becomes as easy as:","category":"page"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"model1 = Sem(\n    specification = partable,\n    data = data_1\n)\n\nmodel2 = deepcopy(replace_observed(model; data = data_2, specification = partable))\n\nmodels = [model1, model2]\nfits = Vector{SemFit}(undef, 2)\n\nThreads.@threads for i in 1:2\n    fits[i] = fit(models[i])\nend","category":"page"},{"location":"performance/simulation/#API","page":"Simulation studies","title":"API","text":"","category":"section"},{"location":"performance/simulation/","page":"Simulation studies","title":"Simulation studies","text":"replace_observed\nupdate_observed","category":"page"},{"location":"performance/simulation/#StructuralEquationModels.replace_observed","page":"Simulation studies","title":"StructuralEquationModels.replace_observed","text":"(1) replace_observed(model::AbstractSemSingle; kwargs...)\n\n(2) replace_observed(model::AbstractSemSingle, observed; kwargs...)\n\nReturn a new model with swaped observed part.\n\nArguments\n\nmodel::AbstractSemSingle: model to swap the observed part of.\nkwargs: additional keyword arguments; typically includes data and specification\nobserved: Either an object of subtype of SemObserved or a subtype of SemObserved\n\nExamples\n\nSee the online documentation on Replace observed data.\n\n\n\n\n\n","category":"function"},{"location":"performance/simulation/#StructuralEquationModels.update_observed","page":"Simulation studies","title":"StructuralEquationModels.update_observed","text":"update_observed(to_update, observed::SemObserved; kwargs...)\n\nUpdate a SemImplied, SemLossFunction or SemOptimizer object to use a SemObserved object.\n\nExamples\n\nSee the online documentation on Replace observed data.\n\nImplementation\n\nYou can provide a method for this function when defining a new type, for more information on this see the online developer documentation on Update observed data.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/construction/build_by_parts/#Build-by-parts","page":"Build by parts","title":"Build by parts","text":"","category":"section"},{"location":"tutorials/construction/build_by_parts/","page":"Build by parts","title":"Build by parts","text":"You can always build a model by parts - that is, you construct the observed, implied, loss and optimizer part seperately.","category":"page"},{"location":"tutorials/construction/build_by_parts/","page":"Build by parts","title":"Build by parts","text":"As an example on how this works, we will build A first model in parts.","category":"page"},{"location":"tutorials/construction/build_by_parts/","page":"Build by parts","title":"Build by parts","text":"First, we specify the model just as usual:","category":"page"},{"location":"tutorials/construction/build_by_parts/","page":"Build by parts","title":"Build by parts","text":"using StructuralEquationModels\n\ndata = example_data(\"political_democracy\")\n\nobs_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlat_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → dem65\n\n    # variances\n    _(obs_vars) ↔ _(obs_vars)\n    _(lat_vars) ↔ _(lat_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = lat_vars, \n    observed_vars = obs_vars)","category":"page"},{"location":"tutorials/construction/build_by_parts/","page":"Build by parts","title":"Build by parts","text":"Now, we construct the different parts:","category":"page"},{"location":"tutorials/construction/build_by_parts/","page":"Build by parts","title":"Build by parts","text":"# observed ---------------------------------------------------------------------------------\nobserved = SemObservedData(specification = partable, data = data)\n\n# implied ------------------------------------------------------------------------------------\nimplied_ram = RAM(specification = partable)\n\n# loss -------------------------------------------------------------------------------------\nml = SemML(observed = observed)\n\nloss_ml = SemLoss(ml)\n\n# optimizer -------------------------------------------------------------------------------------\noptimizer = SemOptimizerOptim()\n\n# model ------------------------------------------------------------------------------------\n\nmodel_ml = Sem(observed, implied_ram, loss_ml)\n\nfit(optimizer, model_ml)","category":"page"},{"location":"tutorials/construction/outer_constructor/#Outer-Constructor","page":"Outer Constructor","title":"Outer Constructor","text":"","category":"section"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"We already have seen the outer constructor in action in A first model:","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = Sem(\n    specification = partable,\n    data = data\n)\n\n# output\n\nStructural Equation Model\n- Loss Functions\n   SemML\n- Fields\n   observed:  SemObservedData\n   implied:   RAM","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"The output of this call tells you exactly what model you just constructed (i.e. what the loss functions, observed, implied and optimizer parts are).","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"As you can see, by default, we use maximum likelihood estimation abd the RAM implied type. To choose something different, you can provide it as a keyword argument:","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = Sem(\n    specification = partable,\n    data = data,\n    observed = ...,\n    implied = ...,\n    loss = ...,\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"For example, to construct a model for weighted least squares estimation that uses symbolic precomputation, write","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = Sem(\n    specification = partable,\n    data = data,\n    implied = RAMSymbolic,\n    loss = SemWLS,\n    optimizer = SemOptimizerOptim\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"In the section on Our Concept of a Structural Equation Model, we go over the different options you have for each part of the model, and in API - model parts we explain each option in detail. Let's make another example: to use full information maximum likelihood information (FIML), we use","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = Sem(\n    specification = partable,\n    data = data,\n    loss = SemFIML,\n    observed = SemObservedMissing,\n    meanstructure = true\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"You may also provide addition arguments for specific parts of the model. For example, WLS estimation uses per default","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"W = frac12 D^T(S^-1otimes S^-1)D","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"as the weight matrix, where D is the so-called duplication matrix and S is the observed covariance matrix. However, you can pass any other weight matrix you want (e.g., UWL, DWLS, ADF estimation) as a keyword argument:","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"W = ...\n\nmodel = Sem(\n    specification = partable,\n    data = data,\n    implied = RAMSymbolic,\n    loss = SemWLS,\n    wls_weight_matrix = W\n)\n","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"To see what additional keyword arguments are supported, you can consult the documentation of the specific part of the model (either in the REPL by typing ? to enter the help mode and then typing the name of the thing you want to know something about, or in the online section API - model parts):","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"julia>?\n\nhelp>SemObservedMissing\n\n# output\n\n  For observed data with missing values.\n\n  Constructor\n  ≡≡≡≡≡≡≡≡≡≡≡\n\n  SemObservedMissing(;\n      data,\n      observed_vars = nothing,\n      specification = nothing,\n      kwargs...)\n\n  Arguments\n  ≡≡≡≡≡≡≡≡≡\n\n    •  specification: optional SEM model specification\n       (SemSpecification)\n\n    •  data: observed data\n\n    •  observed_vars::Vector{Symbol}: column names of the data (if\n       the object passed as data does not have column names, i.e. is\n       not a data frame)\n\n  ────────────────────────────────────────────────────────────────────────\n\nExtended help is available with `??SemObservedMissing`","category":"page"},{"location":"tutorials/construction/outer_constructor/#Optimize-loss-functions-without-analytic-gradient","page":"Outer Constructor","title":"Optimize loss functions without analytic gradient","text":"","category":"section"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"For loss functions without analytic gradients, it is possible to use finite difference approximation or automatic differentiation. All loss functions provided in the package do have analytic gradients (and some even hessians or approximations thereof), so there is no need do use this feature if you are only working with them. However, if you implement your own loss function, you do not have to provide analytic gradients.","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"To use finite difference approximation, you may construct your model just as before, but swap the Sem constructor for SemFiniteDiff. For example","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"model = SemFiniteDiff(\n    specification = partable,\n    data = data\n)","category":"page"},{"location":"tutorials/construction/outer_constructor/","page":"Outer Constructor","title":"Outer Constructor","text":"constructs a model that will use finite difference approximation if you estimate the parameters via fit(model).","category":"page"},{"location":"performance/mixed_differentiation/#Mixed-analytical-and-automatic-differentiation","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"","category":"section"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"This way of specifying our model is not ideal, however, because now also the maximum likelihood loss function lives inside a SemFiniteDiff model, and this means even though we have defined analytical gradients for it, we do not make use of them.","category":"page"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"A more efficient way is therefore to specify our model as an ensemble model: ","category":"page"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"model_ml = Sem(\n    specification = partable,\n    data = data,\n    loss = SemML\n)\n\nmodel_ridge = SemFiniteDiff(\n    specification = partable,\n    data = data,\n    loss = myridge\n)\n\nmodel_ml_ridge = SemEnsemble(model_ml, model_ridge)\n\nmodel_ml_ridge_fit = fit(model_ml_ridge)","category":"page"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"The results of both methods will be the same, but we can verify that the computation costs differ (the package BenchmarkTools has to be installed for this):","category":"page"},{"location":"performance/mixed_differentiation/","page":"Mixed analytical and automatic differentiation","title":"Mixed analytical and automatic differentiation","text":"using BenchmarkTools\n\n@benchmark fit(model)\n\n@benchmark fit(model_ml_ridge)","category":"page"},{"location":"tutorials/inspection/inspection/#Model-inspection","page":"Model Inspection","title":"Model inspection","text":"","category":"section"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"using StructuralEquationModels\n\nobserved_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    # loadings\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    # latent regressions\n    ind60 → dem60\n    dem60 → dem65\n    ind60 → dem65\n\n    # variances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    # covariances\n    y1 ↔ y5\n    y2 ↔ y4 + y6\n    y3 ↔ y7\n    y8 ↔ y4 + y6\n\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = latent_vars,\n    observed_vars = observed_vars)\n\ndata = example_data(\"political_democracy\")\n\nmodel = Sem(\n    specification = partable,\n    data = data\n)\n\nmodel_fit = fit(model)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"After you fitted a model,","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"model_fit = fit(model)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"you end up with an object of type SemFit.","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"You can get some more information about it by using the details function:","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"details(model_fit)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"To compute fit measures, we use","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"fit_measures(model_fit)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"or compute them individually:","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"AIC(model_fit)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"A list of available Fit measures is at the end of this page.","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"To inspect the parameter estimates, we can update a ParameterTable object and call details on it:","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"update_estimate!(partable, model_fit)\n\ndetails(partable)","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"We can also update the ParameterTable object with other information via update_partable!. For example, if we want to compare hessian-based and bootstrap-based standard errors, we may write","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"se_bs = se_bootstrap(model_fit; n_boot = 20)\nse_he = se_hessian(model_fit)\n\nupdate_partable!(partable, :se_hessian, param_labels(model_fit), se_he)\nupdate_partable!(partable, :se_bootstrap, param_labels(model_fit), se_bs)\n\ndetails(partable)","category":"page"},{"location":"tutorials/inspection/inspection/#Export-results","page":"Model Inspection","title":"Export results","text":"","category":"section"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"You may convert a ParameterTable to a DataFrame and use the DataFrames package for further analysis (or to save it to your hard drive).","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"using DataFrames\n\nparameters_df = DataFrame(partable)","category":"page"},{"location":"tutorials/inspection/inspection/#API-model-inspection","page":"Model Inspection","title":"API - model inspection","text":"","category":"section"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"details\nupdate_estimate!\nupdate_partable!","category":"page"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.details","page":"Model Inspection","title":"StructuralEquationModels.details","text":"(1) details(sem_fit::SemFit; show_fitmeasures = false)\n\n(2) details(partable::AbstractParameterTable; ...)\n\nPrint information about (1) a fitted SEM or (2) a parameter table to stdout.\n\nExtended help\n\nAddition keyword arguments\n\ndigits = 2: controls precision of printed estimates, standard errors, etc.\ncolor = :light_cyan: color of some parts of the printed output. Can be adjusted for readability.\nsecondary_color = :light_yellow\nshow_variables = true\nshow_columns = nothing: columns names to include in the output e.g.[:from, :to, :estimate])\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.update_estimate!","page":"Model Inspection","title":"StructuralEquationModels.update_estimate!","text":"update_estimate!(\n    partable::AbstractParameterTable,\n    fit::SemFit)\n\nWrite parameter estimates from fit to the :estimate column of partable\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.update_partable!","page":"Model Inspection","title":"StructuralEquationModels.update_partable!","text":"update_partable!(partable::AbstractParameterTable, param_labels::Vector{Symbol}, params, column)\n\nWrite parameter values into column of partable.\n\nThe param_labels and params vectors define the pairs of  parameters, which are being matched to the :param column of the partable.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#Additional-functions","page":"Model Inspection","title":"Additional functions","text":"","category":"section"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"Additional functions that can be used to extract information from a SemFit object:","category":"page"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"SemFit\nparams\nparam_labels\nnparams\nnsamples\nnobserved_vars","category":"page"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.SemFit","page":"Model Inspection","title":"StructuralEquationModels.SemFit","text":"SemFit\n\nFitted structural equation model.\n\nInterfaces\n\nminimum(::SemFit) -> minimum objective value\nsolution(::SemFit) -> parameter estimates\nstart_val(::SemFit) -> starting values\nmodel(::SemFit)\noptimization_result(::SemFit)\noptimizer(::SemFit) -> optimization algorithm\nn_iterations(::SemFit) -> number of iterations\nconvergence(::SemFit) -> convergence properties\n\n\n\n\n\n","category":"type"},{"location":"tutorials/inspection/inspection/#StatsAPI.params","page":"Model Inspection","title":"StatsAPI.params","text":"params(model)\n\nReturn all parameters of a model.\n\n\n\n\n\nparams(partable::ParameterTable) -> Vector{Symbol}\n\nReturn the vector of SEM model parameter identifiers.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.param_labels","page":"Model Inspection","title":"StructuralEquationModels.param_labels","text":"param_labels(semobj) -> Vector{Symbol}\n\nReturn the vector of parameter labels (in the same order as params).\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.nparams","page":"Model Inspection","title":"StructuralEquationModels.nparams","text":"nparams(semobj)\n\nReturn the number of parameters in a SEM model associated with semobj.\n\nSee also params.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.nsamples","page":"Model Inspection","title":"StructuralEquationModels.nsamples","text":"nsamples(semobj)\n\nReturn the number of samples (observed data points).\n\nFor ensemble models, return the sum over all submodels.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.nobserved_vars","page":"Model Inspection","title":"StructuralEquationModels.nobserved_vars","text":"nobserved_vars(semobj)\n\nReturn the number of observed variables in a SEM model associated with semobj.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#Fit-measures","page":"Model Inspection","title":"Fit measures","text":"","category":"section"},{"location":"tutorials/inspection/inspection/","page":"Model Inspection","title":"Model Inspection","text":"fit_measures\nAIC\nBIC\nχ²\ndof\nminus2ll\np_value\nRMSEA","category":"page"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.fit_measures","page":"Model Inspection","title":"StructuralEquationModels.fit_measures","text":"fit_measures(sem_fit, args...)\n\nReturn a default set of fit measures or the fit measures passed as args....\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.AIC","page":"Model Inspection","title":"StructuralEquationModels.AIC","text":"AIC(sem_fit::SemFit)\n\nReturn the akaike information criterion.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.BIC","page":"Model Inspection","title":"StructuralEquationModels.BIC","text":"BIC(sem_fit::SemFit)\n\nReturn the bayesian information criterion.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.χ²","page":"Model Inspection","title":"StructuralEquationModels.χ²","text":"χ²(sem_fit::SemFit)\n\nReturn the χ² value.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StatsAPI.dof","page":"Model Inspection","title":"StatsAPI.dof","text":"dof(model::StatisticalModel)\n\nReturn the number of degrees of freedom consumed in the model, including when applicable the intercept and the distribution's dispersion parameter.\n\n\n\n\n\ndof(sem_fit::SemFit)\ndof(model::AbstractSem)\n\nReturn the degrees of freedom.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.minus2ll","page":"Model Inspection","title":"StructuralEquationModels.minus2ll","text":"minus2ll(sem_fit::SemFit)\n\nReturn the negative 2* log likelihood.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.p_value","page":"Model Inspection","title":"StructuralEquationModels.p_value","text":"p(sem_fit::SemFit)\n\nReturn the p value computed from the χ² test statistic.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/inspection/inspection/#StructuralEquationModels.RMSEA","page":"Model Inspection","title":"StructuralEquationModels.RMSEA","text":"RMSEA(sem_fit::SemFit)\n\nReturn the RMSEA.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/regularization/regularization/#Regularization","page":"Regularization","title":"Regularization","text":"","category":"section"},{"location":"tutorials/regularization/regularization/#Setup","page":"Regularization","title":"Setup","text":"","category":"section"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"For ridge regularization, you can simply use SemRidge as an additional loss function  (for example, a model with the loss functions SemML and SemRidge corresponds to ridge-regularized maximum likelihood estimation).","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"For lasso, elastic net and (far) beyond, you can load the ProximalAlgorithms.jl and ProximalOperators.jl packages alongside StructuralEquationModels:","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"using StructuralEquationModels, ProximalAlgorithms, ProximalOperators","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"using Pkg\nPkg.add(\"ProximalAlgorithms\")\nPkg.add(\"ProximalOperators\")\n\nusing StructuralEquationModels, ProximalAlgorithms, ProximalOperators","category":"page"},{"location":"tutorials/regularization/regularization/#SemOptimizerProximal","page":"Regularization","title":"SemOptimizerProximal","text":"","category":"section"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"To estimate regularized models, we provide a \"building block\" for the optimizer part, called SemOptimizerProximal. It connects our package to the ProximalAlgorithms.jl optimization backend, providing so-called proximal optimization algorithms.  Those can handle, amongst other things, various forms of regularization.","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"It can be used as","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"SemOptimizerProximal(\n    algorithm = ProximalAlgorithms.PANOC(),\n    operator_g,\n    operator_h = nothing\n    )","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"The proximal operator (aka the regularization function) can be passed as operator_g. The available Algorithms are listed here.","category":"page"},{"location":"tutorials/regularization/regularization/#First-example-lasso","page":"Regularization","title":"First example - lasso","text":"","category":"section"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"To show how it works, let's revisit A first model:","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"observed_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]\nlatent_vars = [:ind60, :dem60, :dem65]\n\ngraph = @StenoGraph begin\n\n    ind60 → fixed(1)*x1 + x2 + x3\n    dem60 → fixed(1)*y1 + y2 + y3 + y4\n    dem65 → fixed(1)*y5 + y6 + y7 + y8\n\n    dem60 ← ind60\n    dem65 ← dem60\n    dem65 ← ind60\n\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars) ↔ _(latent_vars)\n\n    y1 ↔ label(:cov_15)*y5\n    y2 ↔ label(:cov_24)*y4 + label(:cov_26)*y6\n    y3 ↔ label(:cov_37)*y7\n    y4 ↔ label(:cov_48)*y8\n    y6 ↔ label(:cov_68)*y8\n\nend\n\npartable = ParameterTable(\n    graph,\n    latent_vars = latent_vars, \n    observed_vars = observed_vars\n)\n\ndata = example_data(\"political_democracy\")\n\nmodel = Sem(\n    specification = partable,\n    data = data\n)","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"We labeled the covariances between the items because we want to regularize those:","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"ind = getindex.(\n    [param_indices(model)], \n    [:cov_15, :cov_24, :cov_26, :cov_37, :cov_48, :cov_68])","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"In the following, we fit the same model with lasso regularization of those covariances. The lasso penalty is defined as","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"sum lambda_i lvert theta_i rvert","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"From the previously linked documentation, we find that lasso regularization is named NormL1 in the ProximalOperators package, and that we can pass an array of hyperparameters (λ) to control the amount of regularization for each parameter. To regularize only the observed item covariances, we define λ as","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"λ = zeros(31); λ[ind] .= 0.02","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"and use SemOptimizerProximal.","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"optimizer_lasso = SemOptimizerProximal(\n    operator_g = NormL1(λ)\n    )\n\nmodel_lasso = Sem(\n    specification = partable,\n    data = data\n)","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"Let's fit the regularized model","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"\nfit_lasso = fit(optimizer_lasso, model_lasso)","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"and compare the solution to unregularizted estimates:","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"sem_fit = fit(model)\n\nupdate_estimate!(partable, sem_fit)\n\nupdate_partable!(partable, :estimate_lasso, param_labels(fit_lasso), solution(fit_lasso))\n\ndetails(partable)","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"Instead of explicitely defining a SemOptimizerProximal object, you can also pass engine = :Proximal and additional keyword arguments to fit:","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"sem_fit = fit(model; engine = :Proximal, operator_g = NormL1(λ))","category":"page"},{"location":"tutorials/regularization/regularization/#Second-example-mixed-l1-and-l0-regularization","page":"Regularization","title":"Second example - mixed l1 and l0 regularization","text":"","category":"section"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"You can choose to penalize different parameters with different types of regularization functions. Let's use the lasso again on the covariances, but additionally penalyze the error variances of the observed items via l0 regularization.","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"The l0 penalty is defined as","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"lambda mathrmnnz(theta)","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"To define a sup of separable proximal operators (i.e. no parameter is penalized twice), we can use SlicedSeparableSum from the ProximalOperators package:","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"prox_operator = SlicedSeparableSum((NormL0(20.0), NormL1(0.02), NormL0(0.0)), ([ind], [9:11], [vcat(1:8, 12:25)]))\n\nmodel_mixed = Sem(\n    specification = partable,\n    data = data,    \n)\n\nfit_mixed = fit(model_mixed; engine = :Proximal, operator_g = prox_operator)","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"Let's again compare the different results:","category":"page"},{"location":"tutorials/regularization/regularization/","page":"Regularization","title":"Regularization","text":"update_partable!(partable, :estimate_mixed, param_labels(fit_mixed), solution(fit_mixed))\n\ndetails(partable)","category":"page"},{"location":"performance/mkl/#Use-MKL","page":"MKL","title":"Use MKL","text":"","category":"section"},{"location":"performance/mkl/","page":"MKL","title":"MKL","text":"Depending on the machine and the specific models, we sometimes observed large performance benefits from using MKL as a backend for matrix operations.  Fortunately, this is very simple to do in julia, so you can just try it out and check if turns out to be beneficial in your use case.","category":"page"},{"location":"performance/mkl/","page":"MKL","title":"MKL","text":"We install the MKL.jl package:","category":"page"},{"location":"performance/mkl/","page":"MKL","title":"MKL","text":"using Pkg; Pkg.add(\"MKL\")","category":"page"},{"location":"performance/mkl/","page":"MKL","title":"MKL","text":"Whenever we execute using MKL in a julia session, from now on MKL will be used as a backend. To check the installation:","category":"page"},{"location":"performance/mkl/","page":"MKL","title":"MKL","text":"using LinearAlgebra\n\nBLAS.get_config()\n\nusing MKL\n\nBLAS.get_config()","category":"page"},{"location":"performance/mkl/","page":"MKL","title":"MKL","text":"To check the performance implications for fitting a SEM, you can use the BenchmarkTools package:","category":"page"},{"location":"performance/mkl/","page":"MKL","title":"MKL","text":"using BenchmarkTools\n\n@benchmark fit($your_model)\n\nusing MKL\n\n@benchmark fit($your_model)","category":"page"},{"location":"tutorials/fitting/fitting/#Model-fitting","page":"Model Fitting","title":"Model fitting","text":"","category":"section"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"As we saw in A first model, after you have build a model, you can fit it via","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"model_fit = fit(model)\n\n# output\n\nFitted Structural Equation Model \n=============================================== \n--------------------- Model ------------------- \n\nStructural Equation Model \n- Loss Functions \n   SemML\n- Fields \n   observed:  SemObservedData \n   implied:   RAM \n   optimizer: SemOptimizerOptim \n\n------------- Optimization result ------------- \n\n * Status: success\n\n * Candidate solution\n    Final objective value:     2.120543e+01\n\n * Found with\n    Algorithm:     L-BFGS\n\n * Convergence measures\n    |x - x'|               = 6.13e-05 ≰ 1.5e-08\n    |x - x'|/|x'|          = 8.21e-06 ≰ 0.0e+00\n    |f(x) - f(x')|         = 1.05e-09 ≰ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 4.94e-11 ≤ 1.0e-10\n    |g(x)|                 = 2.48e-05 ≰ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    175\n    f(x) calls:    524\n    ∇f(x) calls:   524","category":"page"},{"location":"tutorials/fitting/fitting/#Choosing-an-optimizer","page":"Model Fitting","title":"Choosing an optimizer","text":"","category":"section"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"To choose a different optimizer, you can call fit with the keyword argument engine = ..., and pass additional keyword arguments:","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"using Optim\n\nmodel_fit = fit(model; engine = :Optim, algorithm = BFGS())","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"Available options for engine are :Optim, :NLopt and :Proximal, where :NLopt and :Proximal are only available if the NLopt.jl and ProximalAlgorithms.jl packages are loaded respectively.","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"The available keyword arguments are listed in the sections Using Optim.jl, Using NLopt.jl and Regularization.","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"Alternative, you can also explicitely define a SemOptimizer and pass it as the first argument to fit:","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"my_optimizer = SemOptimizerOptim(algorithm = BFGS())\n\nfit(my_optimizer, model)","category":"page"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"You may also optionally specify Starting values.","category":"page"},{"location":"tutorials/fitting/fitting/#API-model-fitting","page":"Model Fitting","title":"API - model fitting","text":"","category":"section"},{"location":"tutorials/fitting/fitting/","page":"Model Fitting","title":"Model Fitting","text":"fit","category":"page"},{"location":"tutorials/fitting/fitting/#StatsAPI.fit","page":"Model Fitting","title":"StatsAPI.fit","text":"Fit a statistical model.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/concept/#Our-Concept-of-a-Structural-Equation-Model","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"In our package, every Structural Equation Model (Sem) consists of three parts (four, if you count the optimizer):","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"(Image: SEM concept)","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"Those parts are interchangable building blocks (like 'Legos'), i.e. there are different pieces available you can choose as the observed slot of the model, and stick them together with other pieces that can serve as the implied part.","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"The observed part is for observed data, the implied part is what the model implies about your data (e.g. the model implied covariance matrix), and the loss part compares the observed data and implied properties (e.g. weighted least squares difference between the observed and implied covariance matrix). The optimizer part is not part of the model itself, but it is needed to fit the model as it connects to the optimization backend (e.g. the type of optimization algorithm used).","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"For example, to build a model for maximum likelihood estimation with the NLopt optimization suite as a backend you would choose SemML as a loss function and SemOptimizerNLopt as the optimizer.","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"As you can see, a model can have as many loss functions as you want it to have. We always optimize over their (weighted) sum. So to build a model for ridge regularized full information maximum likelihood estimation, you would choose two loss functions, SemFIML and SemRidge.","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"In julia, everything has a type. To make more precise which objects can be used as the different building blocks, we require them to have a certain type:","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"(Image: SEM concept typed)","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"So everything that can be used as the 'observed' part has to be of type SemObserved.","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"Here is an overview on the available building blocks:","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"SemObserved SemImplied SemLossFunction SemOptimizer\nSemObservedData RAM SemML SemOptimizerOptim\nSemObservedCovariance RAMSymbolic SemWLS SemOptimizerNLopt\nSemObservedMissing ImpliedEmpty SemFIML \n  SemRidge \n  SemConstant ","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"The rest of this page explains the building blocks for each part. First, we explain every part and give an overview on the different options that are available. After that, the API - model parts section serves as a reference for detailed explanations about the different options. (How to stick them together to a final model is explained in the section on Model Construction.)","category":"page"},{"location":"tutorials/concept/#The-observed-part-aka-[SemObserved](@ref)","page":"Our Concept of a Structural Equation Model","title":"The observed part aka SemObserved","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"The observed part contains all necessary information about the observed data. Currently, we have three options: SemObservedData for fully observed datasets, SemObservedCovariance for observed covariances (and means) and SemObservedMissing for data that contains missing values.","category":"page"},{"location":"tutorials/concept/#The-implied-part-aka-[SemImplied](@ref)","page":"Our Concept of a Structural Equation Model","title":"The implied part aka SemImplied","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"The implied part is what your model implies about the data, for example, the model-implied covariance matrix. There are two options at the moment: RAM, which uses the reticular action model to compute the model implied covariance matrix, and RAMSymbolic which does the same but symbolically pre-computes part of the model, which increases subsequent performance in model fitting (see Symbolic precomputation). There is also a third option, ImpliedEmpty that can serve as a 'placeholder' for models that do not need an implied part.","category":"page"},{"location":"tutorials/concept/#The-loss-part-aka-SemLoss","page":"Our Concept of a Structural Equation Model","title":"The loss part aka SemLoss","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"The loss part specifies the objective that is optimized to find the parameter estimates. If it contains more then one loss function (aka SemLossFunction)), we find the parameters by minimizing the sum of loss functions (for example in maximum likelihood estimation + ridge regularization). Available loss functions are","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"SemML: maximum likelihood estimation\nSemWLS: weighted least squares estimation\nSemFIML: full-information maximum likelihood estimation\nSemRidge: ridge regularization","category":"page"},{"location":"tutorials/concept/#The-optimizer-part-aka-SemOptimizer","page":"Our Concept of a Structural Equation Model","title":"The optimizer part aka SemOptimizer","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"The optimizer part of a model connects to the numerical optimization backend used to fit the model.  It can be used to control options like the optimization algorithm, linesearch, stopping criteria, etc.  There are currently three available backends, SemOptimizerOptim connecting to the Optim.jl backend, SemOptimizerNLopt connecting to the NLopt.jl backend and SemOptimizerProximal connecting to ProximalAlgorithms.jl. For more information about the available options see also the tutorials about Using Optim.jl and Using NLopt.jl, as well as Constrained optimization and Regularization .","category":"page"},{"location":"tutorials/concept/#What-to-do-next","page":"Our Concept of a Structural Equation Model","title":"What to do next","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"You now have an understanding of our representation of structural equation models.","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"To learn more about how to use the package, you may visit the remaining tutorials.","category":"page"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"If you want to learn how to extend the package (e.g., add a new loss function), you may visit Extending the package.","category":"page"},{"location":"tutorials/concept/#API-model-parts","page":"Our Concept of a Structural Equation Model","title":"API - model parts","text":"","category":"section"},{"location":"tutorials/concept/#observed","page":"Our Concept of a Structural Equation Model","title":"observed","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"SemObserved\nSemObservedData\nSemObservedCovariance\nSemObservedMissing\nsamples\nobserved_vars\nSemSpecification","category":"page"},{"location":"tutorials/concept/#StructuralEquationModels.SemObserved","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemObserved","text":"Supertype of all objects that can serve as the observed field of a SEM. Pre-processes data and computes sufficient statistics for example. If you have a special kind of data, e.g. ordinal data, you should implement a subtype of SemObserved.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemObservedData","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemObservedData","text":"For observed data without missings.\n\nConstructor\n\nSemObservedData(;\n    data,\n    observed_vars = nothing,\n    specification = nothing,\n    kwargs...)\n\nArguments\n\ndata: observed data – DataFrame or Matrix\nobserved_vars::Vector{Symbol}: column names of the data (if the object passed as data does not have column names, i.e. is not a data frame)\nspecification: optional SEM specification (SemSpecification)\n\nExtended help\n\nInterfaces\n\nnsamples(::SemObservedData) -> number of observed data points\nnobserved_vars(::SemObservedData) -> number of observed (manifested) variables\nsamples(::SemObservedData) -> observed data\nobs_cov(::SemObservedData) -> observed covariance matrix\nobs_mean(::SemObservedData) -> observed mean vector\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemObservedCovariance","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemObservedCovariance","text":"Type alias for SemObservedData that has mean and covariance, but no actual data.\n\nFor instances of SemObservedCovariance samples returns nothing.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemObservedMissing","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemObservedMissing","text":"For observed data with missing values.\n\nConstructor\n\nSemObservedMissing(;\n    data,\n    observed_vars = nothing,\n    specification = nothing,\n    kwargs...)\n\nArguments\n\ndata: observed data\nobserved_vars::Vector{Symbol}: column names of the data (if the object passed as data does not have column names, i.e. is not a data frame)\nspecification: optional SEM model specification (SemSpecification)\n\nExtended help\n\nInterfaces\n\nnsamples(::SemObservedMissing) -> number of samples (data points)\nnobserved_vars(::SemObservedMissing) -> number of observed variables\nsamples(::SemObservedMissing) -> data matrix (contains both measured and missing values)\n\nExpectation maximization\n\nem_mvn!(::SemObservedMissing) can be called to fit a covariance matrix and mean vector to the data using an expectation maximization (EM) algorithm under the assumption of multivariate normality. After, the following methods are available:\n\nem_model(::SemObservedMissing) -> EmMVNModel that contains the covariance matrix and mean vector found via EM\nobs_cov(::SemObservedData) -> EM covariance matrix\nobs_mean(::SemObservedData) -> EM mean vector\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.samples","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.samples","text":"samples(observed::SemObservedData)\n\nGets the matrix of observed data samples. Rows are samples, columns are observed variables.\n\nSee Also\n\nnsamples, observed_vars.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/concept/#StructuralEquationModels.observed_vars","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.observed_vars","text":"observed_vars(semobj) -> Vector{Symbol}\n\nReturn the vector of SEM model observed variable in the order specified by the model, which also should match the order of variables in SemObserved.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/concept/#StructuralEquationModels.SemSpecification","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemSpecification","text":"Base type for all SEM specifications.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#implied","page":"Our Concept of a Structural Equation Model","title":"implied","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"SemImplied\nRAM\nRAMSymbolic\nImpliedEmpty","category":"page"},{"location":"tutorials/concept/#StructuralEquationModels.SemImplied","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemImplied","text":"Supertype of all objects that can serve as the implied field of a SEM. Computes model-implied values that should be compared with the observed data to find parameter estimates, e. g. the model implied covariance or mean. If you would like to implement a different notation, e.g. LISREL, you should implement a subtype of SemImplied.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.RAM","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.RAM","text":"Model implied covariance and means via RAM notation.\n\nConstructor\n\nRAM(;specification,\n    meanstructure = false,\n    gradient = true,\n    kwargs...)\n\nArguments\n\nspecification: either a RAMMatrices or ParameterTable object\nmeanstructure::Bool: does the model have a meanstructure?\ngradient::Bool: is gradient-based optimization used\n\nExtended help\n\nRAM notation\n\nThe model implied covariance matrix is computed as\n\n    Sigma = F(I-A)^-1S(I-A)^-TF^T\n\nand for models with a meanstructure, the model implied means are computed as\n\n    mu = F(I-A)^-1M\n\nInterfaces\n\nparam_labels(::RAM)-> vector of parameter labels\nnparams(::RAM) -> number of parameters\nram.Σ -> model implied covariance matrix\nram.μ -> model implied mean vector\n\nRAM matrices for the current parameter values:\n\nram.A\nram.S\nram.F\nram.M\n\nJacobians of RAM matrices w.r.t to the parameter vector θ\n\nram.∇A -> vec(A)θᵀ\nram.∇S -> vec(S)θᵀ\nram.∇M = Mθᵀ\n\nVector of indices of each parameter in the respective RAM matrix:\n\nram.A_indices\nram.S_indices\nram.M_indices\n\nAdditional interfaces\n\nram.F⨉I_A⁻¹ -> F(I-A)^-1\nram.F⨉I_A⁻¹S -> F(I-A)^-1S\nram.I_A -> I-A\n\nOnly available in gradient! calls:\n\nram.I_A⁻¹ -> (I-A)^-1\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.RAMSymbolic","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.RAMSymbolic","text":"Subtype of SemImplied that implements the RAM notation with symbolic precomputation.\n\nConstructor\n\nRAMSymbolic(;\n    specification,\n    vech = false,\n    gradient = true,\n    hessian = false,\n    approximate_hessian = false,\n    meanstructure = false,\n    kwargs...)\n\nArguments\n\nspecification: either a RAMMatrices or ParameterTable object\nmeanstructure::Bool: does the model have a meanstructure?\ngradient::Bool: is gradient-based optimization used\nhessian::Bool: is hessian-based optimization used\napproximate_hessian::Bool: for hessian based optimization: should the hessian be approximated\nvech::Bool: should the half-vectorization of Σ be computed (instead of the full matrix)   (automatically set to true if any of the loss functions is SemWLS)\n\nExtended help\n\nInterfaces\n\nparam_labels(::RAMSymbolic)-> vector of parameter ids\nnparams(::RAMSymbolic) -> number of parameters\nram.Σ -> model implied covariance matrix\nram.μ -> model implied mean vector\n\nJacobians (only available in gradient! calls)\n\nram.∇Σ -> vec(Σ)θᵀ\nram.∇μ -> μθᵀ\nram.∇Σ_function -> function to overwrite ∇Σ in place,   i.e. ∇Σ_function(∇Σ, θ). Typically, you do not want to use this but simply   query ram.∇Σ.\n\nHessians The computation of hessians is more involved. Therefore, we desribe it in the online documentation,  and the respective interfaces are omitted here.\n\nRAM notation\n\nThe model implied covariance matrix is computed as\n\n    Sigma = F(I-A)^-1S(I-A)^-TF^T\n\nand for models with a meanstructure, the model implied means are computed as\n\n    mu = F(I-A)^-1M\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.ImpliedEmpty","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.ImpliedEmpty","text":"Empty placeholder for models that don't need an implied part. (For example, models that only regularize parameters.)\n\nConstructor\n\nImpliedEmpty(;specification, kwargs...)\n\nArguments\n\nspecification: either a RAMMatrices or ParameterTable object\n\nExamples\n\nA multigroup model with ridge regularization could be specified as a SemEnsemble with one model per group and an additional model with ImpliedEmpty and SemRidge for the regularization part.\n\nExtended help\n\nInterfaces\n\nparam_labels(::ImpliedEmpty)-> Vector of parameter labels\nnparams(::ImpliedEmpty) -> Number of parameters\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#loss-functions","page":"Our Concept of a Structural Equation Model","title":"loss functions","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"SemLoss\nSemLossFunction\nSemML\nSemFIML\nSemWLS\nSemRidge\nSemConstant","category":"page"},{"location":"tutorials/concept/#StructuralEquationModels.SemLoss","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemLoss","text":"SemLoss(args...; loss_weights = nothing, ...)\n\nConstructs the loss field of a SEM. Can contain multiple SemLossFunctions, the model is optimized over their sum. See also SemLossFunction.\n\nArguments\n\nargs...: Multiple SemLossFunctions.\nloss_weights::Vector: Weights for each loss function. Defaults to unweighted optimization.\n\nExamples\n\nmy_ml_loss = SemML(...)\nmy_ridge_loss = SemRidge(...)\nmy_loss = SemLoss(SemML, SemRidge; loss_weights = [1.0, 2.0])\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemLossFunction","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemLossFunction","text":"Supertype for all loss functions of SEMs. If you want to implement a custom loss function, it should be a subtype of SemLossFunction.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemML","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemML","text":"Maximum likelihood estimation.\n\nConstructor\n\nSemML(;observed, meanstructure = false, approximate_hessian = false, kwargs...)\n\nArguments\n\nobserved::SemObserved: the observed part of the model\nmeanstructure::Bool: does the model have a meanstructure?\napproximate_hessian::Bool: if hessian-based optimization is used, should the hessian be swapped for an approximation\n\nExamples\n\nmy_ml = SemML(observed = my_observed)\n\nInterfaces\n\nAnalytic gradients are available, and for models without a meanstructure and RAMSymbolic implied type, also analytic hessians.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemFIML","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemFIML","text":"Full information maximum likelihood estimation. Can handle observed data with missings.\n\nConstructor\n\nSemFIML(;observed, specification, kwargs...)\n\nArguments\n\nobserved::SemObservedMissing: the observed part of the model\nspecification: either a RAMMatrices or ParameterTable object\n\nExamples\n\nmy_fiml = SemFIML(observed = my_observed, specification = my_parameter_table)\n\nInterfaces\n\nAnalytic gradients are available.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemWLS","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemWLS","text":"Weighted least squares estimation. At the moment only available with the RAMSymbolic implied type.\n\nConstructor\n\nSemWLS(;\n    observed,\n    meanstructure = false,\n    wls_weight_matrix = nothing,\n    wls_weight_matrix_mean = nothing,\n    approximate_hessian = false,\n    kwargs...)\n\nArguments\n\nobserved: the SemObserved part of the model\nmeanstructure::Bool: does the model have a meanstructure?\napproximate_hessian::Bool: should the hessian be swapped for an approximation\nwls_weight_matrix: the weight matrix for weighted least squares.   Defaults to GLS estimation (05*(D^T*kron(SS)*D) where D is the duplication matrix   and S is the inverse of the observed covariance matrix)\nwls_weight_matrix_mean: the weight matrix for the mean part of weighted least squares.   Defaults to GLS estimation (the inverse of the observed covariance matrix)\n\nExamples\n\nmy_wls = SemWLS(observed = my_observed)\n\nInterfaces\n\nAnalytic gradients are available, and for models without a meanstructure also analytic hessians.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemRidge","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemRidge","text":"Ridge regularization.\n\nConstructor\n\nSemRidge(;α_ridge, which_ridge, nparams, parameter_type = Float64, implied = nothing, kwargs...)\n\nArguments\n\nα_ridge: hyperparameter for penalty term\nwhich_ridge::Vector: Vector of parameter labels (Symbols) or indices that indicate which parameters should be regularized.\nnparams::Int: number of parameters of the model\nimplied::SemImplied: implied part of the model\nparameter_type: type of the parameters\n\nExamples\n\nmy_ridge = SemRidge(;α_ridge = 0.02, which_ridge = [:λ₁, :λ₂, :ω₂₃], nparams = 30, implied = my_implied)\n\nInterfaces\n\nAnalytic gradients and hessians are available.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemConstant","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemConstant","text":"Constant loss term. Can be used for comparability to other packages.\n\nConstructor\n\nSemConstant(;constant_loss, kwargs...)\n\nArguments\n\nconstant_loss::Number: constant to add to the objective\n\nExamples\n\n    my_constant = SemConstant(constant_loss = 42.0)\n\nInterfaces\n\nAnalytic gradients and hessians are available.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#optimizer","page":"Our Concept of a Structural Equation Model","title":"optimizer","text":"","category":"section"},{"location":"tutorials/concept/","page":"Our Concept of a Structural Equation Model","title":"Our Concept of a Structural Equation Model","text":"SemOptimizer\nSemOptimizerOptim\nSemOptimizerNLopt\nSemOptimizerProximal","category":"page"},{"location":"tutorials/concept/#StructuralEquationModels.SemOptimizer","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemOptimizer","text":"Supertype of all objects that can serve as the optimizer field of a SEM. Connects the SEM to its optimization backend and controls options like the optimization algorithm. If you want to connect the SEM package to a new optimization backend, you should implement a subtype of SemOptimizer.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemOptimizerOptim","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemOptimizerOptim","text":"SemOptimizerOptim{A, B} <: SemOptimizer{:Optim}\n\nConnects to Optim.jl as the optimization backend.\n\nConstructor\n\nSemOptimizerOptim(;\n    algorithm = LBFGS(),\n    options = Optim.Options(;f_tol = 1e-10, x_tol = 1.5e-8),\n    kwargs...)\n\nArguments\n\nalgorithm: optimization algorithm from Optim.jl\noptions::Optim.Options: options for the optimization algorithm\n\nUsage\n\nAll algorithms and options from the Optim.jl library are available, for more information see the Optim.jl online documentation.\n\nExamples\n\nmy_optimizer = SemOptimizerOptim()\n\n# hessian based optimization with backtracking linesearch and modified initial step size\nusing Optim, LineSearches\n\nmy_newton_optimizer = SemOptimizerOptim(\n    algorithm = Newton(\n        ;linesearch = BackTracking(order=3),\n        alphaguess = InitialHagerZhang()\n    )\n)\n\nExtended help\n\nConstrained optimization\n\nWhen using the Fminbox or SAMIN constrained optimization algorithms, the vector or dictionary of lower and upper bounds for each model parameter can be specified via lower_bounds and upper_bounds keyword arguments. Alternatively, the lower_bound and upper_bound keyword arguments can be used to specify the default bound for all non-variance model parameters, and the variance_lower_bound and variance_upper_bound keyword – for the variance parameters (the diagonal of the S matrix).\n\nInterfaces\n\nalgorithm(::SemOptimizerOptim)\noptions(::SemOptimizerOptim)\n\nImplementation\n\nSubtype of SemOptimizer.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemOptimizerNLopt","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemOptimizerNLopt","text":"Connects to NLopt.jl as the optimization backend. Only usable if NLopt.jl is loaded in the current Julia session!\n\nConstructor\n\nSemOptimizerNLopt(;\n    algorithm = :LD_LBFGS,\n    options = Dict{Symbol, Any}(),\n    local_algorithm = nothing,\n    local_options = Dict{Symbol, Any}(),\n    equality_constraints = Vector{NLoptConstraint}(),\n    inequality_constraints = Vector{NLoptConstraint}(),\n    kwargs...)\n\nArguments\n\nalgorithm: optimization algorithm.\noptions::Dict{Symbol, Any}: options for the optimization algorithm\nlocal_algorithm: local optimization algorithm\nlocal_options::Dict{Symbol, Any}: options for the local optimization algorithm\nequality_constraints::Vector{NLoptConstraint}: vector of equality constraints\ninequality_constraints::Vector{NLoptConstraint}: vector of inequality constraints\n\nExample\n\nmy_optimizer = SemOptimizerNLopt()\n\n# constrained optimization with augmented lagrangian\nmy_constrained_optimizer = SemOptimizerNLopt(;\n    algorithm = :AUGLAG,\n    local_algorithm = :LD_LBFGS,\n    local_options = Dict(:ftol_rel => 1e-6),\n    inequality_constraints = NLoptConstraint(;f = my_constraint, tol = 0.0),\n)\n\nUsage\n\nAll algorithms and options from the NLopt library are available, for more information see the NLopt.jl package and the NLopt online documentation. For information on how to use inequality and equality constraints, see Constrained optimization in our online documentation.\n\nExtended help\n\nInterfaces\n\nalgorithm(::SemOptimizerNLopt)\nlocal_algorithm(::SemOptimizerNLopt)\noptions(::SemOptimizerNLopt)\nlocal_options(::SemOptimizerNLopt)\nequality_constraints(::SemOptimizerNLopt)\ninequality_constraints(::SemOptimizerNLopt)\n\n\n\n\n\n","category":"type"},{"location":"tutorials/concept/#StructuralEquationModels.SemOptimizerProximal","page":"Our Concept of a Structural Equation Model","title":"StructuralEquationModels.SemOptimizerProximal","text":"Connects to ProximalAlgorithms.jl as the optimization backend. Can be used for regularized SEM, for a tutorial see the online docs on Regularization.\n\nConstructor\n\nSemOptimizerProximal(;\n    algorithm = ProximalAlgorithms.PANOC(),\n    operator_g,\n    operator_h = nothing,\n    kwargs...,\n\nArguments\n\nalgorithm: optimization algorithm.\noperator_g: proximal operator (e.g., regularization penalty)\noperator_h: optional second proximal operator\n\nUsage\n\nAll algorithms and operators from ProximalAlgorithms.jl are available, for more information see the online docs on Regularization and the documentation of ProximalAlgorithms.jl / ProximalOperators.jl.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/backends/optim/#Using-Optim.jl","page":"Using Optim.jl","title":"Using Optim.jl","text":"","category":"section"},{"location":"tutorials/backends/optim/","page":"Using Optim.jl","title":"Using Optim.jl","text":"SemOptimizerOptim implements the connection to Optim.jl. It takes two arguments, algorithm and options. The defaults are LBFGS as the optimization algorithm and the standard options from Optim.jl. We can load the Optim and LineSearches packages to choose something different:","category":"page"},{"location":"tutorials/backends/optim/","page":"Using Optim.jl","title":"Using Optim.jl","text":"using Optim, LineSearches\n\nmy_optimizer = SemOptimizerOptim(\n    algorithm = BFGS(\n        linesearch = BackTracking(order=3), \n        alphaguess = InitialHagerZhang()\n        ),\n    options = Optim.Options(show_trace = true) \n    )","category":"page"},{"location":"tutorials/backends/optim/","page":"Using Optim.jl","title":"Using Optim.jl","text":"This optimizer will use BFGS (!not L-BFGS) with a back tracking linesearch and a certain initial step length guess. Also, the trace of the optimization will be printed to the console.","category":"page"},{"location":"tutorials/backends/optim/","page":"Using Optim.jl","title":"Using Optim.jl","text":"To see how to use the optimizer to actually fit a model now, check out the Model fitting section.","category":"page"},{"location":"tutorials/backends/optim/","page":"Using Optim.jl","title":"Using Optim.jl","text":"For a list of all available algorithms and options, we refer to this page of the Optim.jl manual.","category":"page"},{"location":"developer/sem/#Custom-model-types","page":"Custom model types","title":"Custom model types","text":"","category":"section"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"The abstract supertype for all models is AbstractSem, which has two subtypes, AbstractSemSingle{O, I, L} and AbstractSemCollection. Currently, there are 2 subtypes of AbstractSemSingle: Sem, SemFiniteDiff. All subtypes of AbstractSemSingle should have at least observed, implied, loss and optimizer fields, and share their types ({O, I, L}) with the parametric abstract supertype. For example, the SemFiniteDiff type is implemented as","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"struct SemFiniteDiff{O <: SemObserved, I <: SemImplied, L <: SemLoss} <:\n       AbstractSemSingle{O, I, L}\n    observed::O\n    implied::I\n    loss::L\nend","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"Additionally, you can change how objective/gradient/hessian values are computed by providing methods for evaluate!, e.g. from SemFiniteDiff's implementation:","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"evaluate!(objective, gradient, hessian, model::SemFiniteDiff, params) = ...","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"Additionally, we can define constructors like the one in \"src/frontend/specification/Sem.jl\".","category":"page"},{"location":"developer/sem/","page":"Custom model types","title":"Custom model types","text":"It is also possible to add new subtypes for AbstractSemCollection.","category":"page"},{"location":"developer/optimizer/#Custom-optimizer-types","page":"Custom optimizer types","title":"Custom optimizer types","text":"","category":"section"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"The optimizer part of a model connects it to the optimization backend.  Let's say we want to implement a new optimizer as SemOptimizerName. The first part of the implementation is very similar to loss functions, so we just show the implementation of SemOptimizerOptim here as a reference:","category":"page"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"############################################################################################\n### Types and Constructor\n############################################################################################\nmutable struct SemOptimizerName{A, B} <: SemOptimizer{:Name}\n    algorithm::A\n    options::B\nend\n\nSemOptimizer{:Name}(args...; kwargs...) = SemOptimizerName(args...; kwargs...)\n\nSemOptimizerName(;\n    algorithm = LBFGS(),\n    options = Optim.Options(; f_tol = 1e-10, x_tol = 1.5e-8),\n    kwargs...,\n) = SemOptimizerName(algorithm, options)\n\n############################################################################################\n### Recommended methods\n############################################################################################\n\nupdate_observed(optimizer::SemOptimizerName, observed::SemObserved; kwargs...) = optimizer\n\n############################################################################################\n### additional methods\n############################################################################################\n\nalgorithm(optimizer::SemOptimizerName) = optimizer.algorithm\noptions(optimizer::SemOptimizerName) = optimizer.options","category":"page"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"Note that your optimizer is a subtype of SemOptimizer{:Name}, where you can choose a :Name that can later be used as a keyword argument to fit(engine = :Name). Similarly, SemOptimizer{:Name}(args...; kwargs...) = SemOptimizerName(args...; kwargs...) should be defined as well as a constructor that uses only keyword arguments:","category":"page"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"´´´julia SemOptimizerName(;     algorithm = LBFGS(),     options = Optim.Options(; ftol = 1e-10, xtol = 1.5e-8),     kwargs..., ) = SemOptimizerName(algorithm, options) ´´´ A method for update_observed and additional methods might be usefull, but are not necessary.","category":"page"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"Now comes the substantive part: We need to provide a method for fit:","category":"page"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"function fit(\n    optim::SemOptimizerName,\n    model::AbstractSem,\n    start_params::AbstractVector;\n    kwargs...,\n)\n    optimization_result = ...\n\n    ...\n\n    return SemFit(minimum, minimizer, start_params, model, optimization_result)\nend","category":"page"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"The method has to return a SemFit object that consists of the minimum of the objective at the solution, the minimizer (aka parameter estimates), the starting values, the model and the optimization result (which may be anything you desire for your specific backend).","category":"page"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"In addition, you might want to provide methods to access properties of your optimization result:","category":"page"},{"location":"developer/optimizer/","page":"Custom optimizer types","title":"Custom optimizer types","text":"optimizer(res::MyOptimizationResult) = ...\nn_iterations(res::MyOptimizationResult) = ...\nconvergence(res::MyOptimizationResult) = ...","category":"page"},{"location":"tutorials/collection/multigroup/#Multigroup-models","page":"Multigroup models","title":"Multigroup models","text":"","category":"section"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"using StructuralEquationModels","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"As an example, we will fit the model from the lavaan tutorial with loadings constrained to equality across groups.","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"We first load the example data.  We have to make sure that the column indicating the group (here called school) is a vector of Symbols, not strings - so we convert it.","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"dat = example_data(\"holzinger_swineford\")\ndat.school = ifelse.(dat.school .== \"Pasteur\", :Pasteur, :Grant_White)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"dat = example_data(\"holzinger_swineford\")\ndat.school = ifelse.(dat.school .== \"Pasteur\", :Pasteur, :Grant_White)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"We then specify our model via the graph interface:","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"latent_vars = [:visual, :textual, :speed]\nobserved_vars = Symbol.(:x, 1:9)\n\ngraph = @StenoGraph begin\n    # measurement model\n    visual  → fixed(1.0, 1.0)*x1 + label(:λ₂, :λ₂)*x2 + label(:λ₃, :λ₃)*x3\n    textual → fixed(1.0, 1.0)*x4 + label(:λ₅, :λ₅)*x5 + label(:λ₆, :λ₆)*x6\n    speed   → fixed(1.0, 1.0)*x7 + label(:λ₈, :λ₈)*x8 + label(:λ₉, :λ₉)*x9\n    # variances and covariances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars)   ⇔ _(latent_vars)\nend","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"latent_vars = [:visual, :textual, :speed]\nobserved_vars = Symbol.(:x, 1:9)\n\ngraph = @StenoGraph begin\n    # measurement model\n    visual  → fixed(1, 1)*x1 + label(:λ₂, :λ₂)*x2 + label(:λ₃, :λ₃)*x3\n    textual → fixed(1, 1)*x4 + label(:λ₅, :λ₅)*x5 + label(:λ₆, :λ₆)*x6\n    speed   → fixed(1, 1)*x7 + label(:λ₈, :λ₈)*x8 + label(:λ₉, :λ₉)*x9\n    # variances and covariances\n    _(observed_vars) ↔ _(observed_vars)\n    _(latent_vars)   ⇔ _(latent_vars)\nend","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"You can pass multiple arguments to fix() and label() for each group. Parameters with the same label (within and across groups) are constrained to be equal. To fix a parameter in one group, but estimate it freely in the other, you may write fix(NaN, 4.3).","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"You can then use the resulting graph to specify an EnsembleParameterTable","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"groups = [:Pasteur, :Grant_White]\n\npartable = EnsembleParameterTable(\n    graph, \n    observed_vars = observed_vars,\n    latent_vars = latent_vars,\n    groups = groups)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"The parameter table can be used to create a SemEnsemble model:","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"model_ml_multigroup = SemEnsemble(\n    specification = partable,\n    data = dat,\n    column = :school,\n    groups = groups)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"note: A different way to specify\nInstead of choosing the workflow \"Graph -> EnsembleParameterTable -> model\", you may also directly specify RAMMatrices for each group (for an example see this test).","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"We now fit the model and inspect the parameter estimates:","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"sem_fit = fit(model_ml_multigroup)\nupdate_estimate!(partable, sem_fit)\ndetails(partable)","category":"page"},{"location":"tutorials/collection/multigroup/","page":"Multigroup models","title":"Multigroup models","text":"Other things you can query about your fitted model (fit measures, standard errors, etc.) are described in the section Model inspection and work the same way for multigroup models.","category":"page"},{"location":"#A-fast-and-flexible-SEM-framework","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"","category":"section"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"StructuralEquationModels.jl is a package for Structural Equation Modeling (SEM) still under active development. It is written for one purpose: Facilitating methodological innovations for SEM. This purpose implies two subgoals for the package: Easy extensibility and speed. You can easily define custom objective functions and other parts of the model. At the same time, it is (very) fast. These properties enable SEM researchers (such as you!) to play around with ideas (extensibility) and run extensive simulations (speed) to evaluate these ideas and users to profit from the resulting innovation.","category":"page"},{"location":"#Get-Started","page":"A fast and flexible SEM framework","title":"Get Started","text":"","category":"section"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"To get started, we recommend the following order:","category":"page"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"install the package (Installation),\nread A first model, and\nget familiar with Our Concept of a Structural Equation Model.","category":"page"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"After that, if you are interested in specifying your own loss function (or other parts), you can proceed with Extending the package.","category":"page"},{"location":"#Target-Group","page":"A fast and flexible SEM framework","title":"Target Group","text":"","category":"section"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"You may consider using this package if you need extensibility and/or speed, e.g.","category":"page"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"you want to extend SEM (e.g. add a new objective function)\nyou want to extend SEM, and your implementation needs to be fast\nyou want to fit the same model(s) to many datasets (bootstrapping, simulation studies)\nyou are planning a study and would like to do power simulations","category":"page"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"For examples of how to use the package, see the Tutorials.","category":"page"},{"location":"#Batteries-Included","page":"A fast and flexible SEM framework","title":"Batteries Included","text":"","category":"section"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"Models you can fit out of the box include","category":"page"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"Linear SEM that can be specified in RAM notation\nML, GLS and FIML estimation\nRidge/Lasso/... Regularization\nMultigroup SEM\nSums of arbitrary loss functions (everything the optimizer can handle)","category":"page"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"We provide fast objective functions, gradients, and for some cases hessians as well as approximations thereof. As a user, you can easily define custom loss functions. For those, you can decide to provide analytical gradients or use finite difference approximation / automatic differentiation. You can choose to mix loss functions natively found in this package and those you provide. In such cases, you optimize over a sum of different objectives (e.g. ML + Ridge). This strategy also applies to gradients, where you may supply analytic gradients or opt for automatic differentiation or mixed analytical and automatic differentiation.","category":"page"},{"location":"#Installation","page":"A fast and flexible SEM framework","title":"Installation","text":"","category":"section"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"You must have julia installed (and we strongly recommend using an IDE of your choice; we like VS Code with the Julia extension).","category":"page"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"To install the latest version of our package, use the following commands:","category":"page"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"julia> ]\npkg> add StructuralEquationModels","category":"page"},{"location":"#Citing-the-package","page":"A fast and flexible SEM framework","title":"Citing the package","text":"","category":"section"},{"location":"","page":"A fast and flexible SEM framework","title":"A fast and flexible SEM framework","text":"To cite our package, go to the GitHub repostory and click on \"Cite this repostiory\" on the right side or see the CSL file.","category":"page"},{"location":"internals/types/#Type-hierarchy","page":"types","title":"Type hierarchy","text":"","category":"section"},{"location":"internals/types/","page":"types","title":"types","text":"The type hierarchy is implemented in \"src/types.jl\".","category":"page"},{"location":"internals/types/","page":"types","title":"types","text":"AbstractSem: the most abstract type in our package","category":"page"},{"location":"internals/types/","page":"types","title":"types","text":"AbstractSemSingle{O, I, L} <: AbstractSem is an abstract parametric type that is a supertype of all single models\nSem: models that do not need automatic differentiation or finite difference approximation\nSemFiniteDiff: models whose gradients and/or hessians should be computed via finite difference approximation\nAbstractSemCollection <: AbstractSem is an abstract supertype of all models that contain multiple AbstractSem submodels","category":"page"},{"location":"internals/types/","page":"types","title":"types","text":"Every AbstractSemSingle has to have SemObserved, SemImplied, and SemLoss fields (and can have additional fields).","category":"page"},{"location":"internals/types/","page":"types","title":"types","text":"SemLoss is a container for multiple SemLossFunctions.","category":"page"},{"location":"complementary/maths/","page":"Mathematical appendix","title":"Mathematical appendix","text":"This page is still empty.","category":"page"}]
}
