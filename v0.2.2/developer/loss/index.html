<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Custom loss functions · StructuralEquationModels.jl</title><meta name="title" content="Custom loss functions · StructuralEquationModels.jl"/><meta property="og:title" content="Custom loss functions · StructuralEquationModels.jl"/><meta property="twitter:title" content="Custom loss functions · StructuralEquationModels.jl"/><meta name="description" content="Documentation for StructuralEquationModels.jl."/><meta property="og:description" content="Documentation for StructuralEquationModels.jl."/><meta property="twitter:description" content="Documentation for StructuralEquationModels.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon_zeta.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="StructuralEquationModels.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">StructuralEquationModels.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">A fast and flexible SEM framework</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/first_model/">A first model</a></li><li><a class="tocitem" href="../../tutorials/concept/">Our Concept of a Structural Equation Model</a></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Model Specification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/specification/specification/">Model specification</a></li><li><a class="tocitem" href="../../tutorials/specification/graph_interface/">Graph interface</a></li><li><a class="tocitem" href="../../tutorials/specification/ram_matrices/">RAMMatrices interface</a></li><li><a class="tocitem" href="../../tutorials/specification/parameter_table/">ParameterTable interface</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Model Construction</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/construction/construction/">Model Construction</a></li><li><a class="tocitem" href="../../tutorials/construction/outer_constructor/">Outer Constructor</a></li><li><a class="tocitem" href="../../tutorials/construction/build_by_parts/">Build by parts</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-5" type="checkbox"/><label class="tocitem" for="menuitem-2-5"><span class="docs-label">Optimization Backends</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/backends/optim/">Using Optim.jl</a></li><li><a class="tocitem" href="../../tutorials/backends/nlopt/">Using NLopt.jl</a></li></ul></li><li><a class="tocitem" href="../../tutorials/fitting/fitting/">Model Fitting</a></li><li><a class="tocitem" href="../../tutorials/inspection/inspection/">Model Inspection</a></li><li><a class="tocitem" href="../../tutorials/meanstructure/">Mean Structures</a></li><li><input class="collapse-toggle" id="menuitem-2-9" type="checkbox"/><label class="tocitem" for="menuitem-2-9"><span class="docs-label">Collections</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/collection/collection/">Collections</a></li><li><a class="tocitem" href="../../tutorials/collection/multigroup/">Multigroup models</a></li></ul></li><li><a class="tocitem" href="../../tutorials/constraints/constraints/">Constraints</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Developer documentation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../extending/">Extending the package</a></li><li class="is-active"><a class="tocitem" href>Custom loss functions</a><ul class="internal"><li><a class="tocitem" href="#Minimal"><span>Minimal</span></a></li><li><a class="tocitem" href="#Convenient"><span>Convenient</span></a></li><li><a class="tocitem" href="#Additional-functionality"><span>Additional functionality</span></a></li><li class="toplevel"><a class="tocitem" href="#Second-example-maximum-likelihood"><span>Second example - maximum likelihood</span></a></li></ul></li><li><a class="tocitem" href="../imply/">Custom imply types</a></li><li><a class="tocitem" href="../optimizer/">Custom optimizer types</a></li><li><a class="tocitem" href="../observed/">Custom observed types</a></li><li><a class="tocitem" href="../sem/">Custom model types</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Advanced tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/regularization/regularization/">Regularization</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">Performance tips</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../performance/sorting/">Model sorting</a></li><li><a class="tocitem" href="../../performance/mkl/">MKL</a></li><li><a class="tocitem" href="../../performance/simulation/">Simulation studies</a></li><li><a class="tocitem" href="../../performance/symbolic/">Symbolic precomputation</a></li><li><a class="tocitem" href="../../performance/starting_values/">Starting values</a></li><li><a class="tocitem" href="../../performance/parametric/">Parametric Types</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">Internals and design</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../internals/internals/">Internals and design</a></li><li><a class="tocitem" href="../../internals/files/">files</a></li><li><a class="tocitem" href="../../internals/types/">types</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">Complementary material</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../complementary/maths/">Mathematical appendix</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Developer documentation</a></li><li class="is-active"><a href>Custom loss functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Custom loss functions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/StructuralEquationModels/StructuralEquationModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/StructuralEquationModels/StructuralEquationModels.jl/blob/main/docs/src/developer/loss.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Custom-loss-functions"><a class="docs-heading-anchor" href="#Custom-loss-functions">Custom loss functions</a><a id="Custom-loss-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-loss-functions" title="Permalink"></a></h1><p>As an example, we will implement ridge regularization. Maximum likelihood estimation with ridge regularization consists of optimizing the objective</p><p class="math-container">\[F_{ML}(\theta) + \alpha \lVert \theta_I \rVert^2_2\]</p><p>Since we allow for the optimization of sums of loss functions, and the maximum likelihood loss function already exists, we only need to implement the ridge part (and additionally get ridge regularization for WLS and FIML estimation for free).</p><h2 id="Minimal"><a class="docs-heading-anchor" href="#Minimal">Minimal</a><a id="Minimal-1"></a><a class="docs-heading-anchor-permalink" href="#Minimal" title="Permalink"></a></h2><p>To define a new loss function, you have to define a new type that is a subtype of <code>SemLossFunction</code>:</p><pre><code class="language-julia hljs">struct Ridge &lt;: SemLossFunction
    α
    I
end</code></pre><p>We store the hyperparameter α and the indices I of the parameters we want to regularize.</p><p>Additionaly, we need to define a <em>method</em> to compute the objective:</p><pre><code class="language-julia hljs">import StructuralEquationModels: objective!

objective!(ridge::Ridge, par, model::AbstractSemSingle) = ridge.α*sum(par[ridge.I].^2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">objective! (generic function with 17 methods)</code></pre><p>That&#39;s all we need to make it work! For example, we can now fit <a href="../../tutorials/first_model/#A-first-model">A first model</a> with ridge regularization:</p><p>We first give some parameters labels to be able to identify them as targets for the regularization:</p><pre><code class="language-julia hljs">observed_vars = [:x1, :x2, :x3, :y1, :y2, :y3, :y4, :y5, :y6, :y7, :y8]
latent_vars = [:ind60, :dem60, :dem65]

graph = @StenoGraph begin

    # loadings
    ind60 → fixed(1)*x1 + x2 + x3
    dem60 → fixed(1)*y1 + y2 + y3 + y4
    dem65 → fixed(1)*y5 + y6 + y7 + y8

    # latent regressions
    ind60 → label(:a)*dem60
    dem60 → label(:b)*dem65
    ind60 → label(:c)*dem65

    # variances
    _(observed_vars) ↔ _(observed_vars)
    _(latent_vars) ↔ _(latent_vars)

    # covariances
    y1 ↔ y5
    y2 ↔ y4 + y6
    y3 ↔ y7
    y8 ↔ y4 + y6

end

partable = ParameterTable(
    latent_vars = latent_vars,
    observed_vars = observed_vars,
    graph = graph)

parameter_indices  = get_identifier_indices([:a, :b, :c], partable)
myridge = Ridge(0.01, parameter_indices)

model = SemFiniteDiff(
    specification = partable,
    data = example_data(&quot;political_democracy&quot;),
    loss = (SemML, myridge)
)

model_fit = sem_fit(model)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Fitted Structural Equation Model 
=============================================== 
--------------------- Model ------------------- 

Structural Equation Model : Finite Diff Approximation
- Loss Functions 
   SemML
   Ridge
- Fields 
   observed:    SemObservedData 
   imply:       RAM 
   optimizer:   SemOptimizerOptim 

------------- Optimization result ------------- 

 * Status: success

 * Candidate solution
    Final objective value:     2.123542e+01

 * Found with
    Algorithm:     L-BFGS

 * Convergence measures
    |x - x&#39;|               = 3.79e-05 ≰ 1.5e-08
    |x - x&#39;|/|x&#39;|          = 5.08e-06 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 1.68e-09 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 7.91e-11 ≤ 1.0e-10
    |g(x)|                 = 6.86e-05 ≰ 1.0e-08

 * Work counters
    Seconds run:   1  (vs limit Inf)
    Iterations:    152
    f(x) calls:    461
    ∇f(x) calls:   461
</code></pre><p>This is one way of specifying the model - we now have <strong>one model</strong> with <strong>multiple loss functions</strong>. Because we did not provide a gradient for <code>Ridge</code>, we have to specify a <code>SemFiniteDiff</code> model that computes numerical gradients with finite difference approximation.</p><p>Note that the last argument to the <code>objective!</code> method is the whole model. Therefore, we can access everything that is stored inside our model everytime we compute the objective value for our loss function. Since ridge regularization is a very easy case, we do not need to do this. But maximum likelihood estimation for example depends on both the observed and the model implied covariance matrix. See <a href="#Second-example-maximum-likelihood">Second example - maximum likelihood</a> for information on how to do that.</p><h3 id="Improve-performance"><a class="docs-heading-anchor" href="#Improve-performance">Improve performance</a><a id="Improve-performance-1"></a><a class="docs-heading-anchor-permalink" href="#Improve-performance" title="Permalink"></a></h3><p>By far the biggest improvements in performance will result from specifying analytical gradients. We can do this for our example:</p><pre><code class="language-julia hljs">import StructuralEquationModels: gradient!

function gradient!(ridge::Ridge, par, model::AbstractSemSingle)
    gradient = zero(par)
    gradient[ridge.I] .= 2*ridge.α*par[ridge.I]
    return gradient
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">gradient! (generic function with 18 methods)</code></pre><p>Now, instead of specifying a <code>SemFiniteDiff</code>, we can use the normal <code>Sem</code> constructor:</p><pre><code class="language-julia hljs">model_new = Sem(
    specification = partable,
    data = example_data(&quot;political_democracy&quot;),
    loss = (SemML, myridge)
)

model_fit = sem_fit(model_new)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Fitted Structural Equation Model 
=============================================== 
--------------------- Model ------------------- 

Structural Equation Model 
- Loss Functions 
   SemML
   Ridge
- Fields 
   observed:    SemObservedData 
   imply:       RAM 
   optimizer:   SemOptimizerOptim 

------------- Optimization result ------------- 

 * Status: success

 * Candidate solution
    Final objective value:     2.123542e+01

 * Found with
    Algorithm:     L-BFGS

 * Convergence measures
    |x - x&#39;|               = 9.38e-06 ≰ 1.5e-08
    |x - x&#39;|/|x&#39;|          = 1.26e-06 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 3.25e-10 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 1.53e-11 ≤ 1.0e-10
    |g(x)|                 = 1.11e-04 ≰ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    163
    f(x) calls:    481
    ∇f(x) calls:   481
</code></pre><p>The results are the same, but we can verify that the computational costs are way lower (for this, the julia package <code>BenchmarkTools</code> has to be installed):</p><pre><code class="language-julia hljs">using BenchmarkTools

@benchmark sem_fit(model)

@benchmark sem_fit(model_new)</code></pre><p>The exact results of those benchmarks are of course highly depended an your system (processor, RAM, etc.), but you should see that the median computation time with analytical gradients drops to about 5% of the computation without analytical gradients.</p><p>Additionally, you may provide analytic hessians by writing a method of the form</p><pre><code class="language-julia hljs">function hessian!(ridge::Ridge, par, model::AbstractSemSingle)
    ...
    return hessian
end</code></pre><p>however, this will only matter if you use an optimization algorithm that makes use of the hessians. Our default algorithmn <code>LBFGS</code> from the package <code>Optim.jl</code> does not use hessians (for example, the <code>Newton</code> algorithmn from the same package does).</p><p>To improve performance even more, you can write a method of the form</p><pre><code class="language-julia hljs">function objective_gradient!(ridge::Ridge, par, model::AbstractSemSingle)
    ...
    return objective, gradient
end</code></pre><p>This is beneficial when the computation of the objective and gradient share common computations. For example, in maximum likelihood estimation, the model implied covariance matrix has to be inverted to both compute the objective and gradient. Whenever the optimization algorithmn asks for the objective value and gradient at the same point, we call <code>objective_gradient!</code> and only have to do the shared computations - in this case the matrix inversion - once.</p><p>If you want to do hessian-based optimization, there are also the following methods:</p><pre><code class="language-julia hljs">function objective_hessian!(ridge::Ridge, par, model::AbstractSemSingle)
    ...
    return objective, hessian
end

function gradient_hessian!(ridge::Ridge, par, model::AbstractSemSingle)
    ...
    return gradient, hessian
end

function objective_gradient_hessian!(ridge::Ridge, par, model::AbstractSemSingle)
    ...
    return objective, gradient, hessian
end</code></pre><h2 id="Convenient"><a class="docs-heading-anchor" href="#Convenient">Convenient</a><a id="Convenient-1"></a><a class="docs-heading-anchor-permalink" href="#Convenient" title="Permalink"></a></h2><p>To be able to build the model with the <a href="../../tutorials/construction/outer_constructor/#Outer-Constructor">Outer Constructor</a>, you need to add a constructor for your loss function that only takes keyword arguments and allows for passing optional additional kewyword arguments. A constructor is just a function that creates a new instance of your type:</p><pre><code class="language-julia hljs">function MyLoss(;arg1 = ..., arg2, kwargs...)
    ...
    return MyLoss(...)
end</code></pre><p>All keyword arguments that a user passes to the Sem constructor are passed to your loss function. In addition, all previously constructed parts of the model (imply and observed part) are passed as keyword arguments as well as the number of parameters <code>n_par = ...</code>, so your constructor may depend on those. For example, the constructor for <code>SemML</code> in our package depends on the additional argument <code>meanstructure</code> as well as the observed part of the model to pre-allocate arrays of the same size as the observed covariance matrix and the observed mean vector: </p><pre><code class="language-julia hljs">function SemML(;observed, meanstructure = false, approx_H = false, kwargs...)

    isnothing(obs_mean(observed)) ?
        meandiff = nothing :
        meandiff = copy(obs_mean(observed))

    return SemML(
        similar(obs_cov(observed)),
        similar(obs_cov(observed)),
        meandiff,
        approx_H,
        Val(meanstructure)
        )
end</code></pre><h2 id="Additional-functionality"><a class="docs-heading-anchor" href="#Additional-functionality">Additional functionality</a><a id="Additional-functionality-1"></a><a class="docs-heading-anchor-permalink" href="#Additional-functionality" title="Permalink"></a></h2><h3 id="Update-observed-data"><a class="docs-heading-anchor" href="#Update-observed-data">Update observed data</a><a id="Update-observed-data-1"></a><a class="docs-heading-anchor-permalink" href="#Update-observed-data" title="Permalink"></a></h3><p>If you are planing a simulation study where you have to fit the <strong>same model</strong> to many <strong>different datasets</strong>, it is computationally beneficial to not build the whole model completely new everytime you change your data. Therefore, we provide a function to update the data of your model, <code>swap_observed(model(semfit); data = new_data)</code>. However, we can not know beforehand in what way your loss function depends on the specific datasets. The solution is to provide a method for <code>update_observed</code>. Since <code>Ridge</code> does not depend on the data at all, this is quite easy:</p><pre><code class="language-julia hljs">import StructuralEquationModels: update_observed

update_observed(ridge::Ridge, observed::SemObserved; kwargs...) = ridge</code></pre><h3 id="Access-additional-information"><a class="docs-heading-anchor" href="#Access-additional-information">Access additional information</a><a id="Access-additional-information-1"></a><a class="docs-heading-anchor-permalink" href="#Access-additional-information" title="Permalink"></a></h3><p>If you want to provide a way to query information about loss functions of your type, you can provide functions for that:</p><pre><code class="language-julia hljs">hyperparameter(ridge::Ridge) = ridge.α
regularization_indices(ridge::Ridge) = ridge.I</code></pre><h1 id="Second-example-maximum-likelihood"><a class="docs-heading-anchor" href="#Second-example-maximum-likelihood">Second example - maximum likelihood</a><a id="Second-example-maximum-likelihood-1"></a><a class="docs-heading-anchor-permalink" href="#Second-example-maximum-likelihood" title="Permalink"></a></h1><p>Let&#39;s make a sligtly more complicated example: we will reimplement maximum likelihood estimation.</p><p>To keep it simple, we only cover models without a meanstructure. The maximum likelihood objective is defined as</p><p class="math-container">\[F_{ML} = \log \det \Sigma_i + \mathrm{tr}\left(\Sigma_{i}^{-1} \Sigma_o \right)\]</p><p>where <span>$\Sigma_i$</span> is the model implied covariance matrix and <span>$\Sigma_o$</span> is the observed covariance matrix. We can query the model implied covariance matrix from the <code>imply</code> par of our model, and the observed covariance matrix from the <code>observed</code> path of our model.</p><p>To get information on what we can access from a certain <code>imply</code> or <code>observed</code> type, we can check it`s documentation an the pages <a href="../../tutorials/concept/#API-model-parts">API - model parts</a> or via the help mode of the REPL:</p><pre><code class="language-julia hljs">julia&gt;?

help?&gt; RAM

help?&gt; SemObservedCommon</code></pre><p>We see that the model implied covariance matrix can be assessed as <code>Σ(imply)</code> and the observed covariance matrix as <code>obs_cov(observed)</code>.</p><p>With this information, we write can implement maximum likelihood optimization as</p><pre><code class="language-julia hljs">struct MaximumLikelihood &lt;: SemLossFunction end

using LinearAlgebra
import StructuralEquationModels: Σ, obs_cov, objective!

function objective!(semml::MaximumLikelihood, parameters, model::AbstractSem)
    # access the model implied and observed covariance matrices
    Σᵢ = Σ(imply(model))
    Σₒ = obs_cov(observed(model))
    # compute the objective
    if isposdef(Symmetric(Σᵢ)) # is the model implied covariance matrix positive definite?
        return logdet(Σᵢ) + tr(inv(Σᵢ)*Σₒ)
    else
        return Inf
    end
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">objective! (generic function with 18 methods)</code></pre><p>to deal with eventual non-positive definiteness of the model implied covariance matrix, we chose the pragmatic way of returning infinity whenever this is the case.</p><p>Let&#39;s specify and fit a model:</p><pre><code class="language-julia hljs">model_ml = SemFiniteDiff(
    specification = partable,
    data = example_data(&quot;political_democracy&quot;),
    loss = MaximumLikelihood()
)

model_fit = sem_fit(model_ml)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Fitted Structural Equation Model 
=============================================== 
--------------------- Model ------------------- 

Structural Equation Model : Finite Diff Approximation
- Loss Functions 
   MaximumLikelihood
- Fields 
   observed:    SemObservedData 
   imply:       RAM 
   optimizer:   SemOptimizerOptim 

------------- Optimization result ------------- 

 * Status: success

 * Candidate solution
    Final objective value:     2.120543e+01

 * Found with
    Algorithm:     L-BFGS

 * Convergence measures
    |x - x&#39;|               = 3.70e-05 ≰ 1.5e-08
    |x - x&#39;|/|x&#39;|          = 4.95e-06 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 2.03e-09 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 9.57e-11 ≤ 1.0e-10
    |g(x)|                 = 6.81e-05 ≰ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    139
    f(x) calls:    430
    ∇f(x) calls:   430
</code></pre><p>If you want to differentiate your own loss functions via automatic differentiation, check out the <a href="https://github.com/StructuralEquationModels/AutoDiffSEM">AutoDiffSEM</a> package (spoiler allert: it&#39;s really easy).</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../extending/">« Extending the package</a><a class="docs-footer-nextpage" href="../imply/">Custom imply types »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Sunday 17 March 2024 11:45">Sunday 17 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
